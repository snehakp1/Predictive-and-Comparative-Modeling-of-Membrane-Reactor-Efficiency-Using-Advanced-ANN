{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FohEokf8c2QO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Input\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gph78bJ46TgL"
      },
      "source": [
        "traingd-ReLu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>membrane area</th>\n",
              "      <th>ch4</th>\n",
              "      <th>co2</th>\n",
              "      <th>n2</th>\n",
              "      <th>o2</th>\n",
              "      <th>mass flow</th>\n",
              "      <th>lhv</th>\n",
              "      <th>pressure</th>\n",
              "      <th>diameter</th>\n",
              "      <th>efficiency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.98</td>\n",
              "      <td>58.4</td>\n",
              "      <td>33.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>8.71</td>\n",
              "      <td>45.7</td>\n",
              "      <td>10</td>\n",
              "      <td>0.42</td>\n",
              "      <td>63.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.08</td>\n",
              "      <td>58.4</td>\n",
              "      <td>33.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>8.71</td>\n",
              "      <td>45.7</td>\n",
              "      <td>10</td>\n",
              "      <td>0.42</td>\n",
              "      <td>63.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.18</td>\n",
              "      <td>58.4</td>\n",
              "      <td>33.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>8.71</td>\n",
              "      <td>45.7</td>\n",
              "      <td>10</td>\n",
              "      <td>0.42</td>\n",
              "      <td>63.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.29</td>\n",
              "      <td>58.4</td>\n",
              "      <td>33.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>8.71</td>\n",
              "      <td>45.7</td>\n",
              "      <td>10</td>\n",
              "      <td>0.42</td>\n",
              "      <td>63.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.68</td>\n",
              "      <td>58.4</td>\n",
              "      <td>33.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>8.71</td>\n",
              "      <td>45.7</td>\n",
              "      <td>10</td>\n",
              "      <td>0.45</td>\n",
              "      <td>62.69</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   membrane area   ch4   co2   n2   o2  mass flow   lhv  pressure  diameter  \\\n",
              "0           1.98  58.4  33.9  3.8  1.1       8.71  45.7        10      0.42   \n",
              "1           2.08  58.4  33.9  3.8  1.1       8.71  45.7        10      0.42   \n",
              "2           2.18  58.4  33.9  3.8  1.1       8.71  45.7        10      0.42   \n",
              "3           2.29  58.4  33.9  3.8  1.1       8.71  45.7        10      0.42   \n",
              "4           1.68  58.4  33.9  3.8  1.1       8.71  45.7        10      0.45   \n",
              "\n",
              "   efficiency  \n",
              "0       63.26  \n",
              "1       63.41  \n",
              "2       63.49  \n",
              "3       63.54  \n",
              "4       62.69  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(r'C:\\Users\\user\\OneDrive\\Desktop\\sneha\\PROJECT\\dataset\\original\\data_set.csv'  )\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZS9LlqozzR-"
      },
      "source": [
        "100,32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfcGTae87dkU",
        "outputId": "80ebfca2-4805-4493-bef6-5199ff397b0a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\anaconda3\\envs\\hydrogen\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 1.1161 - mae: 0.9608 - val_loss: 0.6836 - val_mae: 0.7685\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.5320 - mae: 0.6474 - val_loss: 0.5604 - val_mae: 0.6870\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - loss: 0.4637 - mae: 0.6093 - val_loss: 0.5165 - val_mae: 0.6483\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.4541 - mae: 0.6048 - val_loss: 0.4822 - val_mae: 0.6134\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4010 - mae: 0.5498 - val_loss: 0.4556 - val_mae: 0.5889\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3520 - mae: 0.5041 - val_loss: 0.4341 - val_mae: 0.5648\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3296 - mae: 0.4799 - val_loss: 0.4151 - val_mae: 0.5428\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3267 - mae: 0.4762 - val_loss: 0.3978 - val_mae: 0.5234\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3507 - mae: 0.4833 - val_loss: 0.3813 - val_mae: 0.4998\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2942 - mae: 0.4251 - val_loss: 0.3644 - val_mae: 0.4799\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.2751 - mae: 0.4054 - val_loss: 0.3491 - val_mae: 0.4607\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.2781 - mae: 0.3965 - val_loss: 0.3338 - val_mae: 0.4433\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2556 - mae: 0.3820 - val_loss: 0.3199 - val_mae: 0.4254\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2181 - mae: 0.3358 - val_loss: 0.3053 - val_mae: 0.4089\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2239 - mae: 0.3380 - val_loss: 0.2922 - val_mae: 0.3929\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2042 - mae: 0.3128 - val_loss: 0.2795 - val_mae: 0.3784\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.2234 - mae: 0.3317 - val_loss: 0.2672 - val_mae: 0.3644\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1992 - mae: 0.3022 - val_loss: 0.2549 - val_mae: 0.3536\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1893 - mae: 0.2962 - val_loss: 0.2453 - val_mae: 0.3379\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1875 - mae: 0.2890 - val_loss: 0.2348 - val_mae: 0.3260\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.1986 - mae: 0.3018 - val_loss: 0.2246 - val_mae: 0.3156\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.1560 - mae: 0.2639 - val_loss: 0.2147 - val_mae: 0.3096\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.1722 - mae: 0.2770 - val_loss: 0.2073 - val_mae: 0.3007\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.1594 - mae: 0.2653 - val_loss: 0.1980 - val_mae: 0.2963\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1492 - mae: 0.2566 - val_loss: 0.1910 - val_mae: 0.2904\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.1815 - mae: 0.2914 - val_loss: 0.1855 - val_mae: 0.2830\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1459 - mae: 0.2500 - val_loss: 0.1774 - val_mae: 0.2799\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1274 - mae: 0.2372 - val_loss: 0.1697 - val_mae: 0.2763\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.1236 - mae: 0.2306 - val_loss: 0.1643 - val_mae: 0.2710\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1375 - mae: 0.2465 - val_loss: 0.1593 - val_mae: 0.2652\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.1152 - mae: 0.2225 - val_loss: 0.1548 - val_mae: 0.2607\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.1208 - mae: 0.2348 - val_loss: 0.1490 - val_mae: 0.2589\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1336 - mae: 0.2445 - val_loss: 0.1450 - val_mae: 0.2536\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.1245 - mae: 0.2383 - val_loss: 0.1410 - val_mae: 0.2511\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.1137 - mae: 0.2213 - val_loss: 0.1379 - val_mae: 0.2476\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1211 - mae: 0.2307 - val_loss: 0.1342 - val_mae: 0.2450\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1244 - mae: 0.2401 - val_loss: 0.1315 - val_mae: 0.2424\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.1132 - mae: 0.2217 - val_loss: 0.1275 - val_mae: 0.2405\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1134 - mae: 0.2280 - val_loss: 0.1238 - val_mae: 0.2387\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1056 - mae: 0.2179 - val_loss: 0.1190 - val_mae: 0.2381\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1090 - mae: 0.2244 - val_loss: 0.1177 - val_mae: 0.2326\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.1146 - mae: 0.2339 - val_loss: 0.1155 - val_mae: 0.2303\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.1071 - mae: 0.2204 - val_loss: 0.1135 - val_mae: 0.2280\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.1046 - mae: 0.2189 - val_loss: 0.1106 - val_mae: 0.2264\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.1086 - mae: 0.2270 - val_loss: 0.1079 - val_mae: 0.2248\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1067 - mae: 0.2246 - val_loss: 0.1060 - val_mae: 0.2222\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0973 - mae: 0.2145 - val_loss: 0.1042 - val_mae: 0.2203\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1072 - mae: 0.2293 - val_loss: 0.1011 - val_mae: 0.2186\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.1033 - mae: 0.2222 - val_loss: 0.1009 - val_mae: 0.2160\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0901 - mae: 0.2043 - val_loss: 0.0974 - val_mae: 0.2147\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0996 - mae: 0.2179 - val_loss: 0.0953 - val_mae: 0.2123\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0909 - mae: 0.2079 - val_loss: 0.0946 - val_mae: 0.2101\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0910 - mae: 0.2034 - val_loss: 0.0957 - val_mae: 0.2112\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0916 - mae: 0.2116 - val_loss: 0.0927 - val_mae: 0.2074\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0830 - mae: 0.1953 - val_loss: 0.0883 - val_mae: 0.2066\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0937 - mae: 0.2135 - val_loss: 0.0866 - val_mae: 0.2042\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0879 - mae: 0.2066 - val_loss: 0.0846 - val_mae: 0.2019\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0907 - mae: 0.2155 - val_loss: 0.0844 - val_mae: 0.1995\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0859 - mae: 0.2044 - val_loss: 0.0841 - val_mae: 0.1981\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0839 - mae: 0.2022 - val_loss: 0.0814 - val_mae: 0.1959\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0770 - mae: 0.1886 - val_loss: 0.0797 - val_mae: 0.1941\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0767 - mae: 0.1901 - val_loss: 0.0777 - val_mae: 0.1925\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0780 - mae: 0.1921 - val_loss: 0.0766 - val_mae: 0.1904\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0824 - mae: 0.2002 - val_loss: 0.0746 - val_mae: 0.1890\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0765 - mae: 0.1905 - val_loss: 0.0730 - val_mae: 0.1876\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0738 - mae: 0.1873 - val_loss: 0.0735 - val_mae: 0.1859\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0783 - mae: 0.1926 - val_loss: 0.0712 - val_mae: 0.1840\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0725 - mae: 0.1823 - val_loss: 0.0694 - val_mae: 0.1826\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0698 - mae: 0.1846 - val_loss: 0.0687 - val_mae: 0.1808\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0676 - mae: 0.1768 - val_loss: 0.0693 - val_mae: 0.1802\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0661 - mae: 0.1752 - val_loss: 0.0671 - val_mae: 0.1779\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0653 - mae: 0.1792 - val_loss: 0.0658 - val_mae: 0.1765\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0684 - mae: 0.1846 - val_loss: 0.0639 - val_mae: 0.1747\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0670 - mae: 0.1776 - val_loss: 0.0622 - val_mae: 0.1734\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0594 - mae: 0.1660 - val_loss: 0.0600 - val_mae: 0.1717\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0623 - mae: 0.1730 - val_loss: 0.0578 - val_mae: 0.1708\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0642 - mae: 0.1761 - val_loss: 0.0571 - val_mae: 0.1681\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0582 - mae: 0.1626 - val_loss: 0.0558 - val_mae: 0.1665\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0597 - mae: 0.1716 - val_loss: 0.0569 - val_mae: 0.1650\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0621 - mae: 0.1704 - val_loss: 0.0548 - val_mae: 0.1633\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0530 - mae: 0.1567 - val_loss: 0.0525 - val_mae: 0.1625\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0594 - mae: 0.1688 - val_loss: 0.0526 - val_mae: 0.1597\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0558 - mae: 0.1635 - val_loss: 0.0520 - val_mae: 0.1585\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0497 - mae: 0.1513 - val_loss: 0.0505 - val_mae: 0.1571\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0563 - mae: 0.1625 - val_loss: 0.0487 - val_mae: 0.1561\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0486 - mae: 0.1489 - val_loss: 0.0479 - val_mae: 0.1538\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0516 - mae: 0.1546 - val_loss: 0.0462 - val_mae: 0.1526\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0514 - mae: 0.1537 - val_loss: 0.0459 - val_mae: 0.1499\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0503 - mae: 0.1532 - val_loss: 0.0451 - val_mae: 0.1489\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0547 - mae: 0.1626 - val_loss: 0.0438 - val_mae: 0.1485\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0440 - mae: 0.1441 - val_loss: 0.0434 - val_mae: 0.1464\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0512 - mae: 0.1555 - val_loss: 0.0433 - val_mae: 0.1447\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0431 - mae: 0.1402 - val_loss: 0.0432 - val_mae: 0.1440\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0529 - mae: 0.1631 - val_loss: 0.0405 - val_mae: 0.1421\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0392 - mae: 0.1315 - val_loss: 0.0402 - val_mae: 0.1402\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0466 - mae: 0.1468 - val_loss: 0.0399 - val_mae: 0.1396\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0423 - mae: 0.1445 - val_loss: 0.0384 - val_mae: 0.1382\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0404 - mae: 0.1364 - val_loss: 0.0381 - val_mae: 0.1370\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0402 - mae: 0.1384 - val_loss: 0.0374 - val_mae: 0.1362\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0411 - mae: 0.1408 - val_loss: 0.0360 - val_mae: 0.1350\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\n",
            "Train Metrics:\n",
            "MSE  : 0.0403\n",
            "RMSE : 0.2008\n",
            "R²   : 0.9155\n",
            "\n",
            "Validation Metrics:\n",
            "MSE  : 0.0360\n",
            "RMSE : 0.1897\n",
            "R²   : 0.9368\n",
            "\n",
            "Test Metrics:\n",
            "MSE  : 0.0529\n",
            "RMSE : 0.2300\n",
            "R²   : 0.8971\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Function to load and preprocess data\n",
        "def load_and_preprocess_data(file_path):\n",
        "    # Load data\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop('efficiency', axis=1)\n",
        "    y = df['efficiency']\n",
        "\n",
        "    # Normalize features\n",
        "    scaler_X = MinMaxScaler(feature_range=(-1, 1))\n",
        "    X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "    # Normalize target\n",
        "    scaler_y = MinMaxScaler(feature_range=(-1, 1))\n",
        "    y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "    # Split into train, validation, and test sets\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y\n",
        "\n",
        "# Load and preprocess data first\n",
        "(X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y = load_and_preprocess_data(r'C:\\Users\\user\\OneDrive\\Desktop\\sneha\\PROJECT\\dataset\\original\\data_set.csv'  )\n",
        "\n",
        "# Define the MLP model after loading the data\n",
        "model = Sequential([\n",
        "    Dense(20, activation='relu', input_shape=(X_train.shape[1],)),  # First hidden layer\n",
        "    Dense(40, activation='relu'),  # Second hidden layer\n",
        "    Dense(40, activation='relu'),  # Third hidden layer\n",
        "    Dense(20, activation='relu'),  # Fourth hidden layer\n",
        "    Dense(1)  # Output layer (for regression)\n",
        "])\n",
        "\n",
        "# Compile the model using traingd (SGD without momentum)\n",
        "optimizer = SGD(learning_rate=0.01)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
        "                    validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "# Predict on train, test, and validation data\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_val_pred = model.predict(X_val)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Function to calculate and print MSE, RMSE, and R²\n",
        "def print_metrics(y_true, y_pred, dataset_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"\\n{dataset_name} Metrics:\")\n",
        "    print(f\"MSE  : {mse:.4f}\")\n",
        "    print(f\"RMSE : {rmse:.4f}\")\n",
        "    print(f\"R²   : {r2:.4f}\")\n",
        "\n",
        "# Print metrics for train, validation, and test data\n",
        "print_metrics(y_train, y_train_pred, \"Train\")\n",
        "print_metrics(y_val, y_val_pred, \"Validation\")\n",
        "print_metrics(y_test, y_test_pred, \"Test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuLm4emUz5G5"
      },
      "source": [
        "100,16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtYPqYxsmVUu",
        "outputId": "a0d307a2-e16b-4515-bcf9-9a71a2a1b637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\anaconda3\\envs\\hydrogen\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - loss: 0.4092 - mae: 0.4691 - val_loss: 0.3538 - val_mae: 0.4314\n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2810 - mae: 0.3693 - val_loss: 0.2736 - val_mae: 0.3575\n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2018 - mae: 0.2983 - val_loss: 0.2284 - val_mae: 0.3206\n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1990 - mae: 0.3055 - val_loss: 0.2029 - val_mae: 0.3010\n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1297 - mae: 0.2313 - val_loss: 0.1836 - val_mae: 0.2936\n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1352 - mae: 0.2492 - val_loss: 0.1700 - val_mae: 0.2866\n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1303 - mae: 0.2483 - val_loss: 0.1588 - val_mae: 0.2806\n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1254 - mae: 0.2468 - val_loss: 0.1497 - val_mae: 0.2738\n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1330 - mae: 0.2596 - val_loss: 0.1397 - val_mae: 0.2683\n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1182 - mae: 0.2441 - val_loss: 0.1311 - val_mae: 0.2627\n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0983 - mae: 0.2220 - val_loss: 0.1225 - val_mae: 0.2593\n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0939 - mae: 0.2161 - val_loss: 0.1157 - val_mae: 0.2530\n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1013 - mae: 0.2279 - val_loss: 0.1105 - val_mae: 0.2464\n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0872 - mae: 0.2142 - val_loss: 0.1043 - val_mae: 0.2421\n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0914 - mae: 0.2180 - val_loss: 0.0995 - val_mae: 0.2375\n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0932 - mae: 0.2245 - val_loss: 0.0961 - val_mae: 0.2333\n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0837 - mae: 0.2049 - val_loss: 0.0911 - val_mae: 0.2287\n",
            "Epoch 18/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0636 - mae: 0.1777 - val_loss: 0.0865 - val_mae: 0.2249\n",
            "Epoch 19/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0901 - mae: 0.2251 - val_loss: 0.0830 - val_mae: 0.2202\n",
            "Epoch 20/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0631 - mae: 0.1795 - val_loss: 0.0796 - val_mae: 0.2161\n",
            "Epoch 21/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0655 - mae: 0.1865 - val_loss: 0.0773 - val_mae: 0.2120\n",
            "Epoch 22/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0650 - mae: 0.1856 - val_loss: 0.0733 - val_mae: 0.2084\n",
            "Epoch 23/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0578 - mae: 0.1685 - val_loss: 0.0705 - val_mae: 0.2049\n",
            "Epoch 24/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0681 - mae: 0.1880 - val_loss: 0.0678 - val_mae: 0.2023\n",
            "Epoch 25/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0604 - mae: 0.1819 - val_loss: 0.0652 - val_mae: 0.1988\n",
            "Epoch 26/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0567 - mae: 0.1692 - val_loss: 0.0629 - val_mae: 0.1957\n",
            "Epoch 27/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0589 - mae: 0.1694 - val_loss: 0.0612 - val_mae: 0.1926\n",
            "Epoch 28/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0534 - mae: 0.1638 - val_loss: 0.0590 - val_mae: 0.1895\n",
            "Epoch 29/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0483 - mae: 0.1585 - val_loss: 0.0570 - val_mae: 0.1868\n",
            "Epoch 30/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0626 - mae: 0.1838 - val_loss: 0.0550 - val_mae: 0.1842\n",
            "Epoch 31/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0504 - mae: 0.1505 - val_loss: 0.0543 - val_mae: 0.1822\n",
            "Epoch 32/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0510 - mae: 0.1617 - val_loss: 0.0521 - val_mae: 0.1798\n",
            "Epoch 33/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0328 - mae: 0.1260 - val_loss: 0.0510 - val_mae: 0.1770\n",
            "Epoch 34/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0451 - mae: 0.1520 - val_loss: 0.0492 - val_mae: 0.1748\n",
            "Epoch 35/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0490 - mae: 0.1565 - val_loss: 0.0479 - val_mae: 0.1729\n",
            "Epoch 36/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0373 - mae: 0.1357 - val_loss: 0.0468 - val_mae: 0.1705\n",
            "Epoch 37/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0529 - mae: 0.1619 - val_loss: 0.0458 - val_mae: 0.1685\n",
            "Epoch 38/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0426 - mae: 0.1460 - val_loss: 0.0442 - val_mae: 0.1664\n",
            "Epoch 39/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0475 - mae: 0.1558 - val_loss: 0.0431 - val_mae: 0.1644\n",
            "Epoch 40/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0463 - mae: 0.1542 - val_loss: 0.0420 - val_mae: 0.1624\n",
            "Epoch 41/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0482 - mae: 0.1579 - val_loss: 0.0410 - val_mae: 0.1598\n",
            "Epoch 42/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0477 - mae: 0.1508 - val_loss: 0.0400 - val_mae: 0.1585\n",
            "Epoch 43/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0389 - mae: 0.1403 - val_loss: 0.0390 - val_mae: 0.1564\n",
            "Epoch 44/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0297 - mae: 0.1211 - val_loss: 0.0384 - val_mae: 0.1546\n",
            "Epoch 45/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0332 - mae: 0.1280 - val_loss: 0.0373 - val_mae: 0.1530\n",
            "Epoch 46/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0300 - mae: 0.1203 - val_loss: 0.0365 - val_mae: 0.1514\n",
            "Epoch 47/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0317 - mae: 0.1301 - val_loss: 0.0357 - val_mae: 0.1499\n",
            "Epoch 48/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0273 - mae: 0.1152 - val_loss: 0.0349 - val_mae: 0.1488\n",
            "Epoch 49/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0281 - mae: 0.1145 - val_loss: 0.0342 - val_mae: 0.1480\n",
            "Epoch 50/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0233 - mae: 0.1089 - val_loss: 0.0334 - val_mae: 0.1452\n",
            "Epoch 51/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0377 - mae: 0.1372 - val_loss: 0.0325 - val_mae: 0.1446\n",
            "Epoch 52/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0246 - mae: 0.1121 - val_loss: 0.0317 - val_mae: 0.1424\n",
            "Epoch 53/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0284 - mae: 0.1235 - val_loss: 0.0312 - val_mae: 0.1406\n",
            "Epoch 54/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0274 - mae: 0.1211 - val_loss: 0.0303 - val_mae: 0.1388\n",
            "Epoch 55/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0281 - mae: 0.1194 - val_loss: 0.0296 - val_mae: 0.1380\n",
            "Epoch 56/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0287 - mae: 0.1201 - val_loss: 0.0289 - val_mae: 0.1365\n",
            "Epoch 57/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0273 - mae: 0.1186 - val_loss: 0.0283 - val_mae: 0.1350\n",
            "Epoch 58/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0238 - mae: 0.1087 - val_loss: 0.0277 - val_mae: 0.1338\n",
            "Epoch 59/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0252 - mae: 0.1142 - val_loss: 0.0276 - val_mae: 0.1340\n",
            "Epoch 60/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0239 - mae: 0.1121 - val_loss: 0.0266 - val_mae: 0.1312\n",
            "Epoch 61/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0245 - mae: 0.1165 - val_loss: 0.0259 - val_mae: 0.1296\n",
            "Epoch 62/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0230 - mae: 0.1074 - val_loss: 0.0254 - val_mae: 0.1283\n",
            "Epoch 63/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0242 - mae: 0.1142 - val_loss: 0.0250 - val_mae: 0.1277\n",
            "Epoch 64/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0227 - mae: 0.1118 - val_loss: 0.0244 - val_mae: 0.1258\n",
            "Epoch 65/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0202 - mae: 0.1056 - val_loss: 0.0240 - val_mae: 0.1248\n",
            "Epoch 66/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0213 - mae: 0.1100 - val_loss: 0.0236 - val_mae: 0.1238\n",
            "Epoch 67/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0213 - mae: 0.1088 - val_loss: 0.0230 - val_mae: 0.1224\n",
            "Epoch 68/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0231 - mae: 0.1135 - val_loss: 0.0225 - val_mae: 0.1213\n",
            "Epoch 69/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0152 - mae: 0.0916 - val_loss: 0.0220 - val_mae: 0.1195\n",
            "Epoch 70/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0210 - mae: 0.1078 - val_loss: 0.0215 - val_mae: 0.1181\n",
            "Epoch 71/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0171 - mae: 0.0942 - val_loss: 0.0210 - val_mae: 0.1167\n",
            "Epoch 72/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0164 - mae: 0.0948 - val_loss: 0.0206 - val_mae: 0.1157\n",
            "Epoch 73/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0181 - mae: 0.0991 - val_loss: 0.0203 - val_mae: 0.1148\n",
            "Epoch 74/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0170 - mae: 0.0965 - val_loss: 0.0199 - val_mae: 0.1133\n",
            "Epoch 75/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0170 - mae: 0.0965 - val_loss: 0.0196 - val_mae: 0.1130\n",
            "Epoch 76/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0190 - mae: 0.1046 - val_loss: 0.0193 - val_mae: 0.1116\n",
            "Epoch 77/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0179 - mae: 0.0998 - val_loss: 0.0189 - val_mae: 0.1105\n",
            "Epoch 78/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0154 - mae: 0.0918 - val_loss: 0.0183 - val_mae: 0.1089\n",
            "Epoch 79/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0161 - mae: 0.0935 - val_loss: 0.0180 - val_mae: 0.1078\n",
            "Epoch 80/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0185 - mae: 0.1020 - val_loss: 0.0178 - val_mae: 0.1071\n",
            "Epoch 81/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0137 - mae: 0.0880 - val_loss: 0.0174 - val_mae: 0.1061\n",
            "Epoch 82/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0148 - mae: 0.0879 - val_loss: 0.0175 - val_mae: 0.1057\n",
            "Epoch 83/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0114 - mae: 0.0785 - val_loss: 0.0170 - val_mae: 0.1047\n",
            "Epoch 84/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0112 - mae: 0.0785 - val_loss: 0.0166 - val_mae: 0.1034\n",
            "Epoch 85/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0148 - mae: 0.0912 - val_loss: 0.0163 - val_mae: 0.1024\n",
            "Epoch 86/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0151 - mae: 0.0928 - val_loss: 0.0160 - val_mae: 0.1009\n",
            "Epoch 87/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0128 - mae: 0.0833 - val_loss: 0.0156 - val_mae: 0.0994\n",
            "Epoch 88/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0134 - mae: 0.0865 - val_loss: 0.0156 - val_mae: 0.0993\n",
            "Epoch 89/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0152 - mae: 0.0898 - val_loss: 0.0154 - val_mae: 0.0984\n",
            "Epoch 90/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0121 - mae: 0.0804 - val_loss: 0.0149 - val_mae: 0.0968\n",
            "Epoch 91/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0110 - mae: 0.0753 - val_loss: 0.0147 - val_mae: 0.0962\n",
            "Epoch 92/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0158 - mae: 0.0938 - val_loss: 0.0146 - val_mae: 0.0955\n",
            "Epoch 93/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0141 - mae: 0.0859 - val_loss: 0.0142 - val_mae: 0.0941\n",
            "Epoch 94/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0135 - mae: 0.0847 - val_loss: 0.0141 - val_mae: 0.0937\n",
            "Epoch 95/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0132 - mae: 0.0842 - val_loss: 0.0140 - val_mae: 0.0930\n",
            "Epoch 96/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0126 - mae: 0.0825 - val_loss: 0.0139 - val_mae: 0.0926\n",
            "Epoch 97/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0092 - mae: 0.0720 - val_loss: 0.0134 - val_mae: 0.0919\n",
            "Epoch 98/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0126 - mae: 0.0851 - val_loss: 0.0131 - val_mae: 0.0900\n",
            "Epoch 99/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0127 - mae: 0.0851 - val_loss: 0.0130 - val_mae: 0.0893\n",
            "Epoch 100/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0123 - mae: 0.0814 - val_loss: 0.0129 - val_mae: 0.0885\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            "\n",
            "Train Metrics:\n",
            "MSE  : 0.0105\n",
            "RMSE : 0.1026\n",
            "R²   : 0.9779\n",
            "\n",
            "Validation Metrics:\n",
            "MSE  : 0.0129\n",
            "RMSE : 0.1134\n",
            "R²   : 0.9774\n",
            "\n",
            "Test Metrics:\n",
            "MSE  : 0.0298\n",
            "RMSE : 0.1726\n",
            "R²   : 0.9421\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Function to load and preprocess data\n",
        "def load_and_preprocess_data(file_path):\n",
        "    # Load data\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop('efficiency', axis=1)\n",
        "    y = df['efficiency']\n",
        "\n",
        "    # Normalize features\n",
        "    scaler_X = MinMaxScaler(feature_range=(-1, 1))\n",
        "    X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "    # Normalize target\n",
        "    scaler_y = MinMaxScaler(feature_range=(-1, 1))\n",
        "    y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "    # Split into train, validation, and test sets\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y\n",
        "\n",
        "# Load and preprocess data first\n",
        "(X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y = load_and_preprocess_data(r'C:\\Users\\user\\OneDrive\\Desktop\\sneha\\PROJECT\\dataset\\original\\data_set.csv'  )\n",
        "\n",
        "# Define the MLP model after loading the data\n",
        "model = Sequential([\n",
        "    Dense(20, activation='relu', input_shape=(X_train.shape[1],)),  # First hidden layer\n",
        "    Dense(30, activation='relu'),  # Second hidden layer\n",
        "    Dense(40, activation='relu'),  # Third hidden layer\n",
        "    Dense(20, activation='relu'),  # Fourth hidden layer\n",
        "    Dense(1)  # Output layer (for regression)\n",
        "])\n",
        "\n",
        "# Compile the model using traingd (SGD without momentum)\n",
        "optimizer = SGD(learning_rate=0.01)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=16,\n",
        "                    validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "# Predict on train, test, and validation data\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_val_pred = model.predict(X_val)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Function to calculate and print MSE, RMSE, and R²\n",
        "def print_metrics(y_true, y_pred, dataset_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"\\n{dataset_name} Metrics:\")\n",
        "    print(f\"MSE  : {mse:.4f}\")\n",
        "    print(f\"RMSE : {rmse:.4f}\")\n",
        "    print(f\"R²   : {r2:.4f}\")\n",
        "\n",
        "# Print metrics for train, validation, and test data\n",
        "print_metrics(y_train, y_train_pred, \"Train\")\n",
        "print_metrics(y_val, y_val_pred, \"Validation\")\n",
        "print_metrics(y_test, y_test_pred, \"Test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTSH6qPEj2ox"
      },
      "source": [
        "Traingdm-ReLu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-iQvy7Lj2W3",
        "outputId": "d5016a34-31ce-456a-ddd6-0e85aa7a70df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\anaconda3\\envs\\hydrogen\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 200ms/step - loss: 0.6206 - mae: 0.7196 - val_loss: 0.5205 - val_mae: 0.6425\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.3890 - mae: 0.5341 - val_loss: 0.3007 - val_mae: 0.4468\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2012 - mae: 0.3562 - val_loss: 0.1286 - val_mae: 0.2597\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0926 - mae: 0.2206 - val_loss: 0.0851 - val_mae: 0.1906\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1171 - mae: 0.2135 - val_loss: 0.0926 - val_mae: 0.2352\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0987 - mae: 0.2363 - val_loss: 0.0872 - val_mae: 0.2037\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0709 - mae: 0.1777 - val_loss: 0.0796 - val_mae: 0.2220\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0823 - mae: 0.2060 - val_loss: 0.0927 - val_mae: 0.2011\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0722 - mae: 0.1799 - val_loss: 0.0566 - val_mae: 0.1510\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0732 - mae: 0.1661 - val_loss: 0.0576 - val_mae: 0.1925\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0634 - mae: 0.1913 - val_loss: 0.0445 - val_mae: 0.1439\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0508 - mae: 0.1515 - val_loss: 0.0400 - val_mae: 0.1462\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0395 - mae: 0.1346 - val_loss: 0.0347 - val_mae: 0.1367\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0362 - mae: 0.1362 - val_loss: 0.0264 - val_mae: 0.1132\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0358 - mae: 0.1215 - val_loss: 0.0227 - val_mae: 0.0997\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0249 - mae: 0.1029 - val_loss: 0.0204 - val_mae: 0.0993\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0211 - mae: 0.0979 - val_loss: 0.0172 - val_mae: 0.0983\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0211 - mae: 0.1030 - val_loss: 0.0160 - val_mae: 0.0859\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0167 - mae: 0.0873 - val_loss: 0.0146 - val_mae: 0.0818\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0155 - mae: 0.0840 - val_loss: 0.0164 - val_mae: 0.0921\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0135 - mae: 0.0781 - val_loss: 0.0135 - val_mae: 0.0742\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0118 - mae: 0.0741 - val_loss: 0.0132 - val_mae: 0.0794\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0119 - mae: 0.0726 - val_loss: 0.0127 - val_mae: 0.0764\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0118 - mae: 0.0774 - val_loss: 0.0127 - val_mae: 0.0813\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0108 - mae: 0.0737 - val_loss: 0.0119 - val_mae: 0.0725\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0108 - mae: 0.0696 - val_loss: 0.0117 - val_mae: 0.0717\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0117 - mae: 0.0692 - val_loss: 0.0118 - val_mae: 0.0688\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0120 - mae: 0.0743 - val_loss: 0.0107 - val_mae: 0.0712\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0083 - mae: 0.0634 - val_loss: 0.0104 - val_mae: 0.0634\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0076 - mae: 0.0576 - val_loss: 0.0102 - val_mae: 0.0669\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0090 - mae: 0.0610 - val_loss: 0.0112 - val_mae: 0.0680\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0112 - mae: 0.0722 - val_loss: 0.0123 - val_mae: 0.0831\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0111 - mae: 0.0798 - val_loss: 0.0104 - val_mae: 0.0604\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0094 - mae: 0.0644 - val_loss: 0.0094 - val_mae: 0.0637\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0069 - mae: 0.0547 - val_loss: 0.0089 - val_mae: 0.0589\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0064 - mae: 0.0541 - val_loss: 0.0089 - val_mae: 0.0614\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0074 - mae: 0.0563 - val_loss: 0.0087 - val_mae: 0.0556\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0073 - mae: 0.0564 - val_loss: 0.0086 - val_mae: 0.0626\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0071 - mae: 0.0554 - val_loss: 0.0087 - val_mae: 0.0548\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0075 - mae: 0.0584 - val_loss: 0.0092 - val_mae: 0.0678\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0068 - mae: 0.0591 - val_loss: 0.0107 - val_mae: 0.0681\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0092 - mae: 0.0649 - val_loss: 0.0090 - val_mae: 0.0694\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0073 - mae: 0.0631 - val_loss: 0.0088 - val_mae: 0.0548\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0067 - mae: 0.0554 - val_loss: 0.0079 - val_mae: 0.0599\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0070 - mae: 0.0569 - val_loss: 0.0082 - val_mae: 0.0524\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0061 - mae: 0.0529 - val_loss: 0.0075 - val_mae: 0.0590\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0066 - mae: 0.0564 - val_loss: 0.0072 - val_mae: 0.0493\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0060 - mae: 0.0523 - val_loss: 0.0071 - val_mae: 0.0566\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0071 - mae: 0.0572 - val_loss: 0.0069 - val_mae: 0.0478\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0068 - mae: 0.0545 - val_loss: 0.0065 - val_mae: 0.0511\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0048 - mae: 0.0463 - val_loss: 0.0068 - val_mae: 0.0482\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0057 - mae: 0.0500 - val_loss: 0.0065 - val_mae: 0.0464\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0063 - mae: 0.0526 - val_loss: 0.0067 - val_mae: 0.0569\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0072 - mae: 0.0616 - val_loss: 0.0081 - val_mae: 0.0567\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0060 - mae: 0.0578 - val_loss: 0.0089 - val_mae: 0.0756\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0075 - mae: 0.0678 - val_loss: 0.0074 - val_mae: 0.0535\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0068 - mae: 0.0542 - val_loss: 0.0057 - val_mae: 0.0497\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0051 - mae: 0.0478 - val_loss: 0.0059 - val_mae: 0.0453\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0048 - mae: 0.0466 - val_loss: 0.0056 - val_mae: 0.0499\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0049 - mae: 0.0469 - val_loss: 0.0057 - val_mae: 0.0444\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0057 - mae: 0.0529 - val_loss: 0.0060 - val_mae: 0.0559\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0050 - mae: 0.0496 - val_loss: 0.0060 - val_mae: 0.0454\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0045 - mae: 0.0439 - val_loss: 0.0055 - val_mae: 0.0522\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0047 - mae: 0.0482 - val_loss: 0.0056 - val_mae: 0.0455\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0044 - mae: 0.0458 - val_loss: 0.0050 - val_mae: 0.0460\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0050 - mae: 0.0463 - val_loss: 0.0050 - val_mae: 0.0404\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0044 - mae: 0.0419 - val_loss: 0.0052 - val_mae: 0.0423\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0045 - mae: 0.0463 - val_loss: 0.0046 - val_mae: 0.0441\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0043 - mae: 0.0462 - val_loss: 0.0048 - val_mae: 0.0468\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0056 - mae: 0.0533 - val_loss: 0.0055 - val_mae: 0.0486\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0044 - mae: 0.0480 - val_loss: 0.0048 - val_mae: 0.0493\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0041 - mae: 0.0478 - val_loss: 0.0044 - val_mae: 0.0397\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0036 - mae: 0.0415 - val_loss: 0.0041 - val_mae: 0.0375\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0040 - mae: 0.0414 - val_loss: 0.0040 - val_mae: 0.0393\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0036 - mae: 0.0398 - val_loss: 0.0041 - val_mae: 0.0403\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0043 - mae: 0.0453 - val_loss: 0.0041 - val_mae: 0.0396\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0040 - mae: 0.0427 - val_loss: 0.0039 - val_mae: 0.0365\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0034 - mae: 0.0396 - val_loss: 0.0039 - val_mae: 0.0423\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0036 - mae: 0.0426 - val_loss: 0.0040 - val_mae: 0.0387\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0033 - mae: 0.0396 - val_loss: 0.0038 - val_mae: 0.0416\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0036 - mae: 0.0420 - val_loss: 0.0042 - val_mae: 0.0396\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0043 - mae: 0.0470 - val_loss: 0.0037 - val_mae: 0.0421\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0031 - mae: 0.0373 - val_loss: 0.0036 - val_mae: 0.0355\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0027 - mae: 0.0352 - val_loss: 0.0035 - val_mae: 0.0382\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0028 - mae: 0.0364 - val_loss: 0.0036 - val_mae: 0.0384\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0029 - mae: 0.0400 - val_loss: 0.0043 - val_mae: 0.0413\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0038 - mae: 0.0470 - val_loss: 0.0035 - val_mae: 0.0408\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0034 - mae: 0.0426 - val_loss: 0.0033 - val_mae: 0.0372\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0029 - mae: 0.0375 - val_loss: 0.0032 - val_mae: 0.0335\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0026 - mae: 0.0329 - val_loss: 0.0030 - val_mae: 0.0350\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0026 - mae: 0.0357 - val_loss: 0.0031 - val_mae: 0.0350\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0028 - mae: 0.0364 - val_loss: 0.0030 - val_mae: 0.0345\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0022 - mae: 0.0319 - val_loss: 0.0031 - val_mae: 0.0336\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0028 - mae: 0.0371 - val_loss: 0.0029 - val_mae: 0.0330\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0024 - mae: 0.0338 - val_loss: 0.0029 - val_mae: 0.0324\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0029 - mae: 0.0388 - val_loss: 0.0033 - val_mae: 0.0348\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0032 - mae: 0.0382 - val_loss: 0.0038 - val_mae: 0.0489\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0033 - mae: 0.0453 - val_loss: 0.0049 - val_mae: 0.0479\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0033 - mae: 0.0412 - val_loss: 0.0034 - val_mae: 0.0446\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0030 - mae: 0.0395 - val_loss: 0.0029 - val_mae: 0.0327\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\n",
            "Train Metrics:\n",
            "MSE  : 0.0024\n",
            "RMSE : 0.0487\n",
            "R²   : 0.9950\n",
            "\n",
            "Validation Metrics:\n",
            "MSE  : 0.0029\n",
            "RMSE : 0.0534\n",
            "R²   : 0.9950\n",
            "\n",
            "Test Metrics:\n",
            "MSE  : 0.0114\n",
            "RMSE : 0.1069\n",
            "R²   : 0.9778\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Function to load and preprocess data\n",
        "def load_and_preprocess_data(file_path):\n",
        "    # Load data\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop('efficiency', axis=1)\n",
        "    y = df['efficiency']\n",
        "\n",
        "    # Normalize features\n",
        "    scaler_X = MinMaxScaler(feature_range=(-1, 1))\n",
        "    X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "    # Normalize target\n",
        "    scaler_y = MinMaxScaler(feature_range=(-1, 1))\n",
        "    y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "    # Split into train, validation, and test sets\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y\n",
        "\n",
        "# Load and preprocess data\n",
        "(X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y = load_and_preprocess_data(r'C:\\Users\\user\\OneDrive\\Desktop\\sneha\\PROJECT\\dataset\\original\\data_set.csv'  )\n",
        "\n",
        "# Define the MLP model with new architecture\n",
        "model = Sequential([\n",
        "    Dense(40, activation='relu', input_shape=(X_train.shape[1],)),  # First hidden layer\n",
        "    Dense(40, activation='relu'),  # Second hidden layer\n",
        "    Dense(40, activation='relu'),  # Third hidden layer\n",
        "    Dense(10, activation='relu'),  # Fourth hidden layer\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "# Compile model using traingdm (SGD with momentum)\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9)  # traingdm\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
        "                    validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "# Predict on train, validation, and test data\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_val_pred = model.predict(X_val)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Function to print evaluation metrics\n",
        "def print_metrics(y_true, y_pred, dataset_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"\\n{dataset_name} Metrics:\")\n",
        "    print(f\"MSE  : {mse:.4f}\")\n",
        "    print(f\"RMSE : {rmse:.4f}\")\n",
        "    print(f\"R²   : {r2:.4f}\")\n",
        "\n",
        "# Display metrics\n",
        "print_metrics(y_train, y_train_pred, \"Train\")\n",
        "print_metrics(y_val, y_val_pred, \"Validation\")\n",
        "print_metrics(y_test, y_test_pred, \"Test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JND4X2J60ufd"
      },
      "source": [
        "100,16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E1lAQ8ks5zm",
        "outputId": "0128a91d-ffbe-44fc-c04e-3b49e39abbb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\anaconda3\\envs\\hydrogen\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.3992 - mae: 0.5163 - val_loss: 0.1426 - val_mae: 0.3098\n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1572 - mae: 0.3173 - val_loss: 0.1212 - val_mae: 0.2873\n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1131 - mae: 0.2698 - val_loss: 0.1157 - val_mae: 0.2680\n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0758 - mae: 0.2064 - val_loss: 0.0841 - val_mae: 0.2343\n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0658 - mae: 0.1846 - val_loss: 0.0641 - val_mae: 0.1795\n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0535 - mae: 0.1579 - val_loss: 0.0389 - val_mae: 0.1319\n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0383 - mae: 0.1285 - val_loss: 0.0340 - val_mae: 0.1396\n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0222 - mae: 0.1046 - val_loss: 0.0210 - val_mae: 0.1088\n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0150 - mae: 0.0913 - val_loss: 0.0158 - val_mae: 0.0936\n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0153 - mae: 0.0887 - val_loss: 0.0135 - val_mae: 0.0853\n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0109 - mae: 0.0660 - val_loss: 0.0106 - val_mae: 0.0699\n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0088 - mae: 0.0630 - val_loss: 0.0083 - val_mae: 0.0618\n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0062 - mae: 0.0526 - val_loss: 0.0076 - val_mae: 0.0590\n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0073 - mae: 0.0573 - val_loss: 0.0072 - val_mae: 0.0570\n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0069 - mae: 0.0551 - val_loss: 0.0065 - val_mae: 0.0515\n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0054 - mae: 0.0493 - val_loss: 0.0065 - val_mae: 0.0488\n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0062 - mae: 0.0547 - val_loss: 0.0057 - val_mae: 0.0515\n",
            "Epoch 18/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0068 - mae: 0.0625 - val_loss: 0.0073 - val_mae: 0.0579\n",
            "Epoch 19/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0069 - mae: 0.0571 - val_loss: 0.0067 - val_mae: 0.0641\n",
            "Epoch 20/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0084 - mae: 0.0626 - val_loss: 0.0047 - val_mae: 0.0480\n",
            "Epoch 21/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0047 - mae: 0.0471 - val_loss: 0.0051 - val_mae: 0.0494\n",
            "Epoch 22/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0045 - mae: 0.0508 - val_loss: 0.0061 - val_mae: 0.0501\n",
            "Epoch 23/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0036 - val_mae: 0.0361\n",
            "Epoch 24/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0039 - mae: 0.0415 - val_loss: 0.0054 - val_mae: 0.0496\n",
            "Epoch 25/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0040 - mae: 0.0423 - val_loss: 0.0037 - val_mae: 0.0370\n",
            "Epoch 26/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mae: 0.0411 - val_loss: 0.0050 - val_mae: 0.0406\n",
            "Epoch 27/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0044 - mae: 0.0409 - val_loss: 0.0041 - val_mae: 0.0375\n",
            "Epoch 28/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0445 - val_loss: 0.0042 - val_mae: 0.0409\n",
            "Epoch 29/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0033 - mae: 0.0406 - val_loss: 0.0040 - val_mae: 0.0451\n",
            "Epoch 30/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - loss: 0.0040 - mae: 0.0452 - val_loss: 0.0036 - val_mae: 0.0353\n",
            "Epoch 31/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0030 - mae: 0.0380 - val_loss: 0.0033 - val_mae: 0.0356\n",
            "Epoch 32/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0035 - mae: 0.0422 - val_loss: 0.0037 - val_mae: 0.0365\n",
            "Epoch 33/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0030 - mae: 0.0352 - val_loss: 0.0030 - val_mae: 0.0331\n",
            "Epoch 34/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0326 - val_loss: 0.0033 - val_mae: 0.0403\n",
            "Epoch 35/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0030 - mae: 0.0368 - val_loss: 0.0033 - val_mae: 0.0345\n",
            "Epoch 36/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0023 - mae: 0.0332 - val_loss: 0.0029 - val_mae: 0.0314\n",
            "Epoch 37/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0026 - mae: 0.0335 - val_loss: 0.0032 - val_mae: 0.0327\n",
            "Epoch 38/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0027 - mae: 0.0344 - val_loss: 0.0033 - val_mae: 0.0393\n",
            "Epoch 39/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0029 - mae: 0.0366 - val_loss: 0.0025 - val_mae: 0.0319\n",
            "Epoch 40/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0030 - mae: 0.0372 - val_loss: 0.0027 - val_mae: 0.0320\n",
            "Epoch 41/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0022 - mae: 0.0322 - val_loss: 0.0030 - val_mae: 0.0316\n",
            "Epoch 42/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0019 - mae: 0.0290 - val_loss: 0.0025 - val_mae: 0.0302\n",
            "Epoch 43/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0020 - mae: 0.0289 - val_loss: 0.0027 - val_mae: 0.0336\n",
            "Epoch 44/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0021 - mae: 0.0308 - val_loss: 0.0025 - val_mae: 0.0334\n",
            "Epoch 45/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0296 - val_loss: 0.0026 - val_mae: 0.0360\n",
            "Epoch 46/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0023 - mae: 0.0348 - val_loss: 0.0024 - val_mae: 0.0282\n",
            "Epoch 47/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0021 - val_mae: 0.0294\n",
            "Epoch 48/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0291 - val_loss: 0.0027 - val_mae: 0.0299\n",
            "Epoch 49/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0024 - val_mae: 0.0292\n",
            "Epoch 50/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0018 - mae: 0.0293 - val_loss: 0.0024 - val_mae: 0.0343\n",
            "Epoch 51/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0022 - mae: 0.0324 - val_loss: 0.0034 - val_mae: 0.0427\n",
            "Epoch 52/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0026 - mae: 0.0389 - val_loss: 0.0019 - val_mae: 0.0289\n",
            "Epoch 53/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0021 - mae: 0.0301 - val_loss: 0.0025 - val_mae: 0.0277\n",
            "Epoch 54/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0021 - mae: 0.0325 - val_loss: 0.0018 - val_mae: 0.0279\n",
            "Epoch 55/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0017 - mae: 0.0270 - val_loss: 0.0023 - val_mae: 0.0299\n",
            "Epoch 56/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0013 - mae: 0.0236 - val_loss: 0.0022 - val_mae: 0.0330\n",
            "Epoch 57/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0017 - mae: 0.0310 - val_loss: 0.0025 - val_mae: 0.0357\n",
            "Epoch 58/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0016 - mae: 0.0321 - val_loss: 0.0018 - val_mae: 0.0261\n",
            "Epoch 59/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.0021 - val_mae: 0.0269\n",
            "Epoch 60/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0024 - val_mae: 0.0293\n",
            "Epoch 61/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0258 - val_loss: 0.0019 - val_mae: 0.0301\n",
            "Epoch 62/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0018 - val_mae: 0.0279\n",
            "Epoch 63/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0019 - mae: 0.0302 - val_loss: 0.0022 - val_mae: 0.0313\n",
            "Epoch 64/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 0.0017 - val_mae: 0.0263\n",
            "Epoch 65/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 0.0017 - val_mae: 0.0252\n",
            "Epoch 66/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0017 - mae: 0.0275 - val_loss: 0.0019 - val_mae: 0.0277\n",
            "Epoch 67/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0017 - mae: 0.0268 - val_loss: 0.0017 - val_mae: 0.0247\n",
            "Epoch 68/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 0.0017 - val_mae: 0.0283\n",
            "Epoch 69/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0269 - val_loss: 0.0018 - val_mae: 0.0276\n",
            "Epoch 70/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0013 - mae: 0.0247 - val_loss: 0.0022 - val_mae: 0.0273\n",
            "Epoch 71/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0016 - val_mae: 0.0280\n",
            "Epoch 72/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0012 - mae: 0.0255 - val_loss: 0.0021 - val_mae: 0.0339\n",
            "Epoch 73/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 0.0017 - val_mae: 0.0270\n",
            "Epoch 74/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0012 - mae: 0.0250 - val_loss: 0.0015 - val_mae: 0.0271\n",
            "Epoch 75/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 0.0019 - val_mae: 0.0242\n",
            "Epoch 76/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0017 - mae: 0.0281 - val_loss: 0.0014 - val_mae: 0.0230\n",
            "Epoch 77/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0016 - val_mae: 0.0252\n",
            "Epoch 78/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0013 - mae: 0.0227 - val_loss: 0.0014 - val_mae: 0.0239\n",
            "Epoch 79/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0014 - val_mae: 0.0249\n",
            "Epoch 80/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 0.0014 - val_mae: 0.0237\n",
            "Epoch 81/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0020 - val_mae: 0.0283\n",
            "Epoch 82/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0014 - val_mae: 0.0265\n",
            "Epoch 83/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0015 - mae: 0.0280 - val_loss: 0.0018 - val_mae: 0.0254\n",
            "Epoch 84/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0014 - mae: 0.0254 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 85/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0012 - mae: 0.0248 - val_loss: 0.0015 - val_mae: 0.0231\n",
            "Epoch 86/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0013 - mae: 0.0235 - val_loss: 0.0014 - val_mae: 0.0258\n",
            "Epoch 87/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0012 - mae: 0.0248 - val_loss: 0.0015 - val_mae: 0.0239\n",
            "Epoch 88/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 0.0015 - val_mae: 0.0259\n",
            "Epoch 89/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 0.0016 - val_mae: 0.0255\n",
            "Epoch 90/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 0.0012 - val_mae: 0.0225\n",
            "Epoch 91/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 0.0018 - val_mae: 0.0300\n",
            "Epoch 92/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0010 - mae: 0.0232 - val_loss: 0.0015 - val_mae: 0.0280\n",
            "Epoch 93/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0016 - val_mae: 0.0247\n",
            "Epoch 94/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0011 - mae: 0.0236 - val_loss: 0.0013 - val_mae: 0.0235\n",
            "Epoch 95/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0010 - mae: 0.0218 - val_loss: 0.0015 - val_mae: 0.0234\n",
            "Epoch 96/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 0.0012 - val_mae: 0.0242\n",
            "Epoch 97/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 0.0013 - val_mae: 0.0218\n",
            "Epoch 98/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 0.0014 - val_mae: 0.0235\n",
            "Epoch 99/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0011 - mae: 0.0241 - val_loss: 0.0013 - val_mae: 0.0221\n",
            "Epoch 100/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 7.9188e-04 - mae: 0.0188 - val_loss: 0.0013 - val_mae: 0.0246\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
            "\n",
            "Train Metrics:\n",
            "MSE  : 0.0010\n",
            "RMSE : 0.0315\n",
            "R²   : 0.9979\n",
            "\n",
            "Validation Metrics:\n",
            "MSE  : 0.0013\n",
            "RMSE : 0.0356\n",
            "R²   : 0.9978\n",
            "\n",
            "Test Metrics:\n",
            "MSE  : 0.0320\n",
            "RMSE : 0.1789\n",
            "R²   : 0.9378\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Function to load and preprocess data\n",
        "def load_and_preprocess_data(file_path):\n",
        "    # Load data\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop('efficiency', axis=1)\n",
        "    y = df['efficiency']\n",
        "\n",
        "    # Normalize features\n",
        "    scaler_X = MinMaxScaler(feature_range=(-1, 1))\n",
        "    X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "    # Normalize target\n",
        "    scaler_y = MinMaxScaler(feature_range=(-1, 1))\n",
        "    y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "    # Split into train, validation, and test sets\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y\n",
        "\n",
        "# Load and preprocess data\n",
        "(X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y = load_and_preprocess_data(r'C:\\Users\\user\\OneDrive\\Desktop\\sneha\\PROJECT\\dataset\\original\\data_set.csv'  )\n",
        "\n",
        "# Define the MLP model with new architecture\n",
        "model = Sequential([\n",
        "    Dense(40, activation='relu', input_shape=(X_train.shape[1],)),  # First hidden layer\n",
        "    Dense(40, activation='relu'),  # Second hidden layer\n",
        "    Dense(40, activation='relu'),  # Third hidden layer\n",
        "    Dense(10, activation='relu'),  # Fourth hidden layer\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "# Compile model using traingdm (SGD with momentum)\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9)  # traingdm\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=16,\n",
        "                    validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "# Predict on train, validation, and test data\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_val_pred = model.predict(X_val)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Function to print evaluation metrics\n",
        "def print_metrics(y_true, y_pred, dataset_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"\\n{dataset_name} Metrics:\")\n",
        "    print(f\"MSE  : {mse:.4f}\")\n",
        "    print(f\"RMSE : {rmse:.4f}\")\n",
        "    print(f\"R²   : {r2:.4f}\")\n",
        "\n",
        "# Display metrics\n",
        "print_metrics(y_train, y_train_pred, \"Train\")\n",
        "print_metrics(y_val, y_val_pred, \"Validation\")\n",
        "print_metrics(y_test, y_test_pred, \"Test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZXQOL30jejV"
      },
      "source": [
        "traingdx-Relu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q7l7t_0xkkdY",
        "outputId": "d69aebb9-1e30-4246-b9cf-077af151f8e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\anaconda3\\envs\\hydrogen\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - loss: 0.3409 - mae: 0.5043 - val_loss: 0.3000 - val_mae: 0.4170 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 628ms/step - loss: 0.2367 - mae: 0.3677 - val_loss: 0.2064 - val_mae: 0.3304 - learning_rate: 0.0095\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.1662 - mae: 0.3084 - val_loss: 0.1269 - val_mae: 0.2478 - learning_rate: 0.0090\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244ms/step - loss: 0.1395 - mae: 0.2583 - val_loss: 0.1187 - val_mae: 0.2481 - learning_rate: 0.0086\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 262ms/step - loss: 0.1466 - mae: 0.2822 - val_loss: 0.1202 - val_mae: 0.2646 - learning_rate: 0.0081\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 764ms/step - loss: 0.1242 - mae: 0.2691 - val_loss: 0.1182 - val_mae: 0.2386 - learning_rate: 0.0077\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 236ms/step - loss: 0.1024 - mae: 0.2185 - val_loss: 0.1213 - val_mae: 0.2360 - learning_rate: 0.0074\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371ms/step - loss: 0.1007 - mae: 0.2220 - val_loss: 0.1011 - val_mae: 0.2243 - learning_rate: 0.0070\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292ms/step - loss: 0.1009 - mae: 0.2293 - val_loss: 0.0868 - val_mae: 0.2082 - learning_rate: 0.0066\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0852 - mae: 0.2051 - val_loss: 0.0782 - val_mae: 0.2053 - learning_rate: 0.0063\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0853 - mae: 0.2089 - val_loss: 0.0667 - val_mae: 0.1779 - learning_rate: 0.0060\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0737 - mae: 0.1808 - val_loss: 0.0596 - val_mae: 0.1639 - learning_rate: 0.0057\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 195ms/step - loss: 0.0613 - mae: 0.1608 - val_loss: 0.0570 - val_mae: 0.1611 - learning_rate: 0.0054\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0626 - mae: 0.1641 - val_loss: 0.0519 - val_mae: 0.1549 - learning_rate: 0.0051\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 233ms/step - loss: 0.0525 - mae: 0.1500 - val_loss: 0.0424 - val_mae: 0.1360 - learning_rate: 0.0049\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 292ms/step - loss: 0.0493 - mae: 0.1453 - val_loss: 0.0374 - val_mae: 0.1284 - learning_rate: 0.0046\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 263ms/step - loss: 0.0460 - mae: 0.1398 - val_loss: 0.0391 - val_mae: 0.1449 - learning_rate: 0.0044\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - loss: 0.0348 - mae: 0.1267 - val_loss: 0.0311 - val_mae: 0.1206 - learning_rate: 0.0042\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0302 - mae: 0.1120 - val_loss: 0.0276 - val_mae: 0.1118 - learning_rate: 0.0040\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - loss: 0.0252 - mae: 0.1055 - val_loss: 0.0258 - val_mae: 0.1105 - learning_rate: 0.0038\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0267 - mae: 0.1094 - val_loss: 0.0267 - val_mae: 0.1184 - learning_rate: 0.0036\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - loss: 0.0257 - mae: 0.1110 - val_loss: 0.0221 - val_mae: 0.1008 - learning_rate: 0.0034\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 205ms/step - loss: 0.0258 - mae: 0.1035 - val_loss: 0.0209 - val_mae: 0.0974 - learning_rate: 0.0032\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - loss: 0.0193 - mae: 0.0903 - val_loss: 0.0197 - val_mae: 0.0950 - learning_rate: 0.0031\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 685ms/step - loss: 0.0172 - mae: 0.0884 - val_loss: 0.0185 - val_mae: 0.0931 - learning_rate: 0.0029\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - loss: 0.0193 - mae: 0.0928 - val_loss: 0.0180 - val_mae: 0.0925 - learning_rate: 0.0028\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 278ms/step - loss: 0.0144 - mae: 0.0805 - val_loss: 0.0165 - val_mae: 0.0851 - learning_rate: 0.0026\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 282ms/step - loss: 0.0154 - mae: 0.0787 - val_loss: 0.0155 - val_mae: 0.0820 - learning_rate: 0.0025\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 778ms/step - loss: 0.0156 - mae: 0.0790 - val_loss: 0.0151 - val_mae: 0.0813 - learning_rate: 0.0024\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - loss: 0.0142 - mae: 0.0764 - val_loss: 0.0145 - val_mae: 0.0805 - learning_rate: 0.0023\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - loss: 0.0146 - mae: 0.0747 - val_loss: 0.0143 - val_mae: 0.0807 - learning_rate: 0.0021\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0120 - mae: 0.0715 - val_loss: 0.0138 - val_mae: 0.0791 - learning_rate: 0.0020\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0145 - mae: 0.0812 - val_loss: 0.0133 - val_mae: 0.0778 - learning_rate: 0.0019\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0132 - mae: 0.0729 - val_loss: 0.0131 - val_mae: 0.0770 - learning_rate: 0.0018\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - loss: 0.0109 - mae: 0.0665 - val_loss: 0.0128 - val_mae: 0.0764 - learning_rate: 0.0017\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0138 - mae: 0.0746 - val_loss: 0.0123 - val_mae: 0.0754 - learning_rate: 0.0017\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0116 - mae: 0.0706 - val_loss: 0.0120 - val_mae: 0.0748 - learning_rate: 0.0016\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189ms/step - loss: 0.0137 - mae: 0.0727 - val_loss: 0.0117 - val_mae: 0.0742 - learning_rate: 0.0015\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - loss: 0.0104 - mae: 0.0649 - val_loss: 0.0116 - val_mae: 0.0741 - learning_rate: 0.0014\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - loss: 0.0109 - mae: 0.0664 - val_loss: 0.0115 - val_mae: 0.0740 - learning_rate: 0.0014\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 211ms/step - loss: 0.0120 - mae: 0.0719 - val_loss: 0.0114 - val_mae: 0.0738 - learning_rate: 0.0013\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0117 - mae: 0.0691 - val_loss: 0.0113 - val_mae: 0.0733 - learning_rate: 0.0012\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0097 - mae: 0.0641 - val_loss: 0.0111 - val_mae: 0.0726 - learning_rate: 0.0012\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0111 - mae: 0.0679 - val_loss: 0.0110 - val_mae: 0.0722 - learning_rate: 0.0011\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0108 - mae: 0.0676 - val_loss: 0.0109 - val_mae: 0.0719 - learning_rate: 0.0010\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0124 - mae: 0.0734 - val_loss: 0.0108 - val_mae: 0.0715 - learning_rate: 9.9440e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0110 - mae: 0.0684 - val_loss: 0.0107 - val_mae: 0.0713 - learning_rate: 9.4468e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0114 - mae: 0.0699 - val_loss: 0.0105 - val_mae: 0.0710 - learning_rate: 8.9745e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0101 - mae: 0.0655 - val_loss: 0.0105 - val_mae: 0.0709 - learning_rate: 8.5258e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0083 - mae: 0.0595 - val_loss: 0.0104 - val_mae: 0.0706 - learning_rate: 8.0995e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0112 - mae: 0.0676 - val_loss: 0.0103 - val_mae: 0.0703 - learning_rate: 7.6945e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0092 - mae: 0.0627 - val_loss: 0.0102 - val_mae: 0.0699 - learning_rate: 7.3098e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0113 - mae: 0.0708 - val_loss: 0.0101 - val_mae: 0.0697 - learning_rate: 6.9443e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - loss: 0.0102 - mae: 0.0652 - val_loss: 0.0101 - val_mae: 0.0695 - learning_rate: 6.5971e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0113 - mae: 0.0680 - val_loss: 0.0101 - val_mae: 0.0695 - learning_rate: 6.2672e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0086 - mae: 0.0624 - val_loss: 0.0100 - val_mae: 0.0691 - learning_rate: 5.9539e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0098 - mae: 0.0668 - val_loss: 0.0099 - val_mae: 0.0689 - learning_rate: 5.6562e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0095 - mae: 0.0642 - val_loss: 0.0099 - val_mae: 0.0687 - learning_rate: 5.3734e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0081 - mae: 0.0600 - val_loss: 0.0098 - val_mae: 0.0685 - learning_rate: 5.1047e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0102 - mae: 0.0689 - val_loss: 0.0098 - val_mae: 0.0684 - learning_rate: 4.8495e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0106 - mae: 0.0661 - val_loss: 0.0097 - val_mae: 0.0683 - learning_rate: 4.6070e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0098 - mae: 0.0647 - val_loss: 0.0096 - val_mae: 0.0680 - learning_rate: 4.3766e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0098 - mae: 0.0629 - val_loss: 0.0096 - val_mae: 0.0678 - learning_rate: 4.1578e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0106 - mae: 0.0650 - val_loss: 0.0095 - val_mae: 0.0677 - learning_rate: 3.9499e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0088 - mae: 0.0619 - val_loss: 0.0095 - val_mae: 0.0676 - learning_rate: 3.7524e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0080 - mae: 0.0596 - val_loss: 0.0095 - val_mae: 0.0676 - learning_rate: 3.5648e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0079 - mae: 0.0597 - val_loss: 0.0094 - val_mae: 0.0676 - learning_rate: 3.3866e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0098 - mae: 0.0643 - val_loss: 0.0094 - val_mae: 0.0677 - learning_rate: 3.2172e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0090 - mae: 0.0620 - val_loss: 0.0094 - val_mae: 0.0675 - learning_rate: 3.0564e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0081 - mae: 0.0584 - val_loss: 0.0093 - val_mae: 0.0673 - learning_rate: 2.9035e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0096 - mae: 0.0654 - val_loss: 0.0093 - val_mae: 0.0672 - learning_rate: 2.7584e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0090 - mae: 0.0626 - val_loss: 0.0093 - val_mae: 0.0671 - learning_rate: 2.6205e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0099 - mae: 0.0652 - val_loss: 0.0093 - val_mae: 0.0670 - learning_rate: 2.4894e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0096 - mae: 0.0633 - val_loss: 0.0092 - val_mae: 0.0669 - learning_rate: 2.3650e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0102 - mae: 0.0653 - val_loss: 0.0092 - val_mae: 0.0668 - learning_rate: 2.2467e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - loss: 0.0091 - mae: 0.0645 - val_loss: 0.0092 - val_mae: 0.0667 - learning_rate: 2.1344e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0088 - mae: 0.0612 - val_loss: 0.0092 - val_mae: 0.0666 - learning_rate: 2.0277e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - loss: 0.0087 - mae: 0.0599 - val_loss: 0.0091 - val_mae: 0.0666 - learning_rate: 1.9263e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0095 - mae: 0.0665 - val_loss: 0.0091 - val_mae: 0.0666 - learning_rate: 1.8300e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - loss: 0.0089 - mae: 0.0629 - val_loss: 0.0091 - val_mae: 0.0666 - learning_rate: 1.7385e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - loss: 0.0086 - mae: 0.0610 - val_loss: 0.0091 - val_mae: 0.0666 - learning_rate: 1.6515e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0099 - mae: 0.0658 - val_loss: 0.0091 - val_mae: 0.0666 - learning_rate: 1.5690e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0100 - mae: 0.0678 - val_loss: 0.0091 - val_mae: 0.0665 - learning_rate: 1.4905e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0101 - mae: 0.0656 - val_loss: 0.0091 - val_mae: 0.0665 - learning_rate: 1.4160e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.0081 - mae: 0.0600 - val_loss: 0.0091 - val_mae: 0.0665 - learning_rate: 1.3452e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0087 - mae: 0.0631 - val_loss: 0.0091 - val_mae: 0.0665 - learning_rate: 1.2779e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - loss: 0.0077 - mae: 0.0584 - val_loss: 0.0091 - val_mae: 0.0664 - learning_rate: 1.2140e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0085 - mae: 0.0624 - val_loss: 0.0091 - val_mae: 0.0664 - learning_rate: 1.1533e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0085 - mae: 0.0612 - val_loss: 0.0090 - val_mae: 0.0664 - learning_rate: 1.0957e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0089 - mae: 0.0627 - val_loss: 0.0090 - val_mae: 0.0663 - learning_rate: 1.0409e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0087 - mae: 0.0620 - val_loss: 0.0090 - val_mae: 0.0663 - learning_rate: 9.8884e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0077 - mae: 0.0576 - val_loss: 0.0090 - val_mae: 0.0663 - learning_rate: 9.3939e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 282ms/step - loss: 0.0083 - mae: 0.0601 - val_loss: 0.0090 - val_mae: 0.0662 - learning_rate: 8.9242e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0077 - mae: 0.0577 - val_loss: 0.0090 - val_mae: 0.0662 - learning_rate: 8.4780e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0099 - mae: 0.0654 - val_loss: 0.0090 - val_mae: 0.0662 - learning_rate: 8.0541e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0084 - mae: 0.0596 - val_loss: 0.0090 - val_mae: 0.0662 - learning_rate: 7.6514e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0086 - mae: 0.0633 - val_loss: 0.0090 - val_mae: 0.0662 - learning_rate: 7.2689e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0097 - mae: 0.0665 - val_loss: 0.0090 - val_mae: 0.0661 - learning_rate: 6.9054e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0085 - mae: 0.0620 - val_loss: 0.0090 - val_mae: 0.0661 - learning_rate: 6.5601e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 216ms/step - loss: 0.0087 - mae: 0.0627 - val_loss: 0.0090 - val_mae: 0.0661 - learning_rate: 6.2321e-05\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\n",
            "Train Metrics:\n",
            "MSE  : 0.0089\n",
            "RMSE : 0.0941\n",
            "R²   : 0.9814\n",
            "\n",
            "Validation Metrics:\n",
            "MSE  : 0.0090\n",
            "RMSE : 0.0946\n",
            "R²   : 0.9843\n",
            "\n",
            "Test Metrics:\n",
            "MSE  : 0.0293\n",
            "RMSE : 0.1712\n",
            "R²   : 0.9430\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# Function to load and preprocess data\n",
        "def load_and_preprocess_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    X = df.drop('efficiency', axis=1)\n",
        "    y = df['efficiency']\n",
        "\n",
        "    scaler_X = MinMaxScaler(feature_range=(-1, 1))\n",
        "    X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "    scaler_y = MinMaxScaler(feature_range=(-1, 1))\n",
        "    y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y\n",
        "\n",
        "# Load and preprocess data\n",
        "(X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y = load_and_preprocess_data(r'C:\\Users\\user\\OneDrive\\Desktop\\sneha\\PROJECT\\dataset\\original\\data_set.csv'  )\n",
        "\n",
        "# Define MLP model with updated architecture\n",
        "model = Sequential([\n",
        "    Dense(40, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation='relu'),\n",
        "    Dense(30, activation='relu'),\n",
        "    Dense(40, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# traingdx: SGD with momentum and adaptive learning rate\n",
        "initial_lr = 0.01\n",
        "momentum = 0.9\n",
        "\n",
        "# Learning rate decay function\n",
        "def lr_schedule(epoch, lr):\n",
        "    decay_rate = 0.95\n",
        "    return initial_lr * (decay_rate ** epoch)\n",
        "\n",
        "optimizer = SGD(learning_rate=initial_lr, momentum=momentum)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model with learning rate scheduler\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[LearningRateScheduler(lr_schedule)],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_val_pred = model.predict(X_val)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation function\n",
        "def print_metrics(y_true, y_pred, dataset_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"\\n{dataset_name} Metrics:\")\n",
        "    print(f\"MSE  : {mse:.4f}\")\n",
        "    print(f\"RMSE : {rmse:.4f}\")\n",
        "    print(f\"R²   : {r2:.4f}\")\n",
        "\n",
        "# Display metrics\n",
        "print_metrics(y_train, y_train_pred, \"Train\")\n",
        "print_metrics(y_val, y_val_pred, \"Validation\")\n",
        "print_metrics(y_test, y_test_pred, \"Test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>membrane area</th>\n",
              "      <th>ch4</th>\n",
              "      <th>co2</th>\n",
              "      <th>n2</th>\n",
              "      <th>o2</th>\n",
              "      <th>mass flow</th>\n",
              "      <th>lhv</th>\n",
              "      <th>pressure</th>\n",
              "      <th>diameter</th>\n",
              "      <th>efficiency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.98</td>\n",
              "      <td>58.4</td>\n",
              "      <td>33.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>8.71</td>\n",
              "      <td>45.7</td>\n",
              "      <td>10</td>\n",
              "      <td>0.42</td>\n",
              "      <td>63.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.08</td>\n",
              "      <td>58.4</td>\n",
              "      <td>33.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>8.71</td>\n",
              "      <td>45.7</td>\n",
              "      <td>10</td>\n",
              "      <td>0.42</td>\n",
              "      <td>63.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.18</td>\n",
              "      <td>58.4</td>\n",
              "      <td>33.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>8.71</td>\n",
              "      <td>45.7</td>\n",
              "      <td>10</td>\n",
              "      <td>0.42</td>\n",
              "      <td>63.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.29</td>\n",
              "      <td>58.4</td>\n",
              "      <td>33.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>8.71</td>\n",
              "      <td>45.7</td>\n",
              "      <td>10</td>\n",
              "      <td>0.42</td>\n",
              "      <td>63.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.68</td>\n",
              "      <td>58.4</td>\n",
              "      <td>33.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>8.71</td>\n",
              "      <td>45.7</td>\n",
              "      <td>10</td>\n",
              "      <td>0.45</td>\n",
              "      <td>62.69</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   membrane area   ch4   co2   n2   o2  mass flow   lhv  pressure  diameter  \\\n",
              "0           1.98  58.4  33.9  3.8  1.1       8.71  45.7        10      0.42   \n",
              "1           2.08  58.4  33.9  3.8  1.1       8.71  45.7        10      0.42   \n",
              "2           2.18  58.4  33.9  3.8  1.1       8.71  45.7        10      0.42   \n",
              "3           2.29  58.4  33.9  3.8  1.1       8.71  45.7        10      0.42   \n",
              "4           1.68  58.4  33.9  3.8  1.1       8.71  45.7        10      0.45   \n",
              "\n",
              "   efficiency  \n",
              "0       63.26  \n",
              "1       63.41  \n",
              "2       63.49  \n",
              "3       63.54  \n",
              "4       62.69  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.read_csv(r'C:\\Users\\user\\OneDrive\\Desktop\\sneha\\PROJECT\\dataset\\original\\data_set.csv'  )\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbMj0eBZ1Qmt"
      },
      "source": [
        "100,16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8eqRCnjpd4X",
        "outputId": "2bd940b7-2de7-428d-b545-0726292fe5ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.6170 - mae: 0.6768 - val_loss: 0.2254 - val_mae: 0.4012 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1824 - mae: 0.3405 - val_loss: 0.1295 - val_mae: 0.2596 - learning_rate: 0.0097\n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1064 - mae: 0.2387 - val_loss: 0.0476 - val_mae: 0.1795 - learning_rate: 0.0094\n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0526 - mae: 0.1721 - val_loss: 0.0344 - val_mae: 0.1281 - learning_rate: 0.0091\n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0431 - mae: 0.1337 - val_loss: 0.0268 - val_mae: 0.1250 - learning_rate: 0.0089\n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0232 - mae: 0.1175 - val_loss: 0.0413 - val_mae: 0.1582 - learning_rate: 0.0086\n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0284 - mae: 0.1149 - val_loss: 0.0211 - val_mae: 0.1141 - learning_rate: 0.0083\n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0131 - mae: 0.0782 - val_loss: 0.0144 - val_mae: 0.0902 - learning_rate: 0.0081\n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0066 - mae: 0.0678 - val_loss: 0.0058 - val_mae: 0.0560 - learning_rate: 0.0078\n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0065 - mae: 0.0601 - val_loss: 0.0077 - val_mae: 0.0732 - learning_rate: 0.0076\n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0066 - mae: 0.0601 - val_loss: 0.0056 - val_mae: 0.0592 - learning_rate: 0.0074\n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0591 - val_loss: 0.0051 - val_mae: 0.0528 - learning_rate: 0.0072\n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0054 - val_mae: 0.0530 - learning_rate: 0.0069\n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0505 - val_loss: 0.0041 - val_mae: 0.0472 - learning_rate: 0.0067\n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0520 - val_loss: 0.0038 - val_mae: 0.0492 - learning_rate: 0.0065\n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0038 - mae: 0.0461 - val_loss: 0.0037 - val_mae: 0.0466 - learning_rate: 0.0063\n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0033 - mae: 0.0452 - val_loss: 0.0045 - val_mae: 0.0476 - learning_rate: 0.0061\n",
            "Epoch 18/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0393 - val_loss: 0.0041 - val_mae: 0.0463 - learning_rate: 0.0060\n",
            "Epoch 19/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0394 - val_loss: 0.0031 - val_mae: 0.0425 - learning_rate: 0.0058\n",
            "Epoch 20/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0385 - val_loss: 0.0034 - val_mae: 0.0412 - learning_rate: 0.0056\n",
            "Epoch 21/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0384 - val_loss: 0.0032 - val_mae: 0.0412 - learning_rate: 0.0054\n",
            "Epoch 22/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0030 - val_mae: 0.0434 - learning_rate: 0.0053\n",
            "Epoch 23/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0415 - val_loss: 0.0029 - val_mae: 0.0396 - learning_rate: 0.0051\n",
            "Epoch 24/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0333 - val_loss: 0.0027 - val_mae: 0.0406 - learning_rate: 0.0050\n",
            "Epoch 25/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 - mae: 0.0419 - val_loss: 0.0037 - val_mae: 0.0411 - learning_rate: 0.0048\n",
            "Epoch 26/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0363 - val_loss: 0.0024 - val_mae: 0.0381 - learning_rate: 0.0047\n",
            "Epoch 27/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0337 - val_loss: 0.0030 - val_mae: 0.0398 - learning_rate: 0.0045\n",
            "Epoch 28/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0366 - val_loss: 0.0028 - val_mae: 0.0374 - learning_rate: 0.0044\n",
            "Epoch 29/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0341 - val_loss: 0.0029 - val_mae: 0.0395 - learning_rate: 0.0043\n",
            "Epoch 30/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0024 - val_mae: 0.0367 - learning_rate: 0.0041\n",
            "Epoch 31/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0347 - val_loss: 0.0025 - val_mae: 0.0345 - learning_rate: 0.0040\n",
            "Epoch 32/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0021 - mae: 0.0354 - val_loss: 0.0028 - val_mae: 0.0383 - learning_rate: 0.0039\n",
            "Epoch 33/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0019 - mae: 0.0354 - val_loss: 0.0026 - val_mae: 0.0371 - learning_rate: 0.0038\n",
            "Epoch 34/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0018 - mae: 0.0325 - val_loss: 0.0024 - val_mae: 0.0369 - learning_rate: 0.0037\n",
            "Epoch 35/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0309 - val_loss: 0.0026 - val_mae: 0.0370 - learning_rate: 0.0036\n",
            "Epoch 36/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0016 - mae: 0.0331 - val_loss: 0.0024 - val_mae: 0.0360 - learning_rate: 0.0034\n",
            "Epoch 37/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0018 - mae: 0.0329 - val_loss: 0.0022 - val_mae: 0.0353 - learning_rate: 0.0033\n",
            "Epoch 38/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0320 - val_loss: 0.0026 - val_mae: 0.0374 - learning_rate: 0.0032\n",
            "Epoch 39/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0016 - mae: 0.0312 - val_loss: 0.0022 - val_mae: 0.0340 - learning_rate: 0.0031\n",
            "Epoch 40/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0018 - mae: 0.0318 - val_loss: 0.0026 - val_mae: 0.0375 - learning_rate: 0.0030\n",
            "Epoch 41/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0014 - mae: 0.0294 - val_loss: 0.0022 - val_mae: 0.0343 - learning_rate: 0.0030\n",
            "Epoch 42/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0314 - val_loss: 0.0021 - val_mae: 0.0338 - learning_rate: 0.0029\n",
            "Epoch 43/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0302 - val_loss: 0.0023 - val_mae: 0.0354 - learning_rate: 0.0028\n",
            "Epoch 44/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0301 - val_loss: 0.0024 - val_mae: 0.0351 - learning_rate: 0.0027\n",
            "Epoch 45/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0317 - val_loss: 0.0022 - val_mae: 0.0344 - learning_rate: 0.0026\n",
            "Epoch 46/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0322 - val_loss: 0.0023 - val_mae: 0.0345 - learning_rate: 0.0025\n",
            "Epoch 47/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0308 - val_loss: 0.0021 - val_mae: 0.0342 - learning_rate: 0.0025\n",
            "Epoch 48/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0313 - val_loss: 0.0022 - val_mae: 0.0339 - learning_rate: 0.0024\n",
            "Epoch 49/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0292 - val_loss: 0.0022 - val_mae: 0.0341 - learning_rate: 0.0023\n",
            "Epoch 50/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0291 - val_loss: 0.0022 - val_mae: 0.0333 - learning_rate: 0.0022\n",
            "Epoch 51/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0304 - val_loss: 0.0022 - val_mae: 0.0346 - learning_rate: 0.0022\n",
            "Epoch 52/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0275 - val_loss: 0.0022 - val_mae: 0.0335 - learning_rate: 0.0021\n",
            "Epoch 53/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0291 - val_loss: 0.0021 - val_mae: 0.0338 - learning_rate: 0.0021\n",
            "Epoch 54/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0282 - val_loss: 0.0020 - val_mae: 0.0329 - learning_rate: 0.0020\n",
            "Epoch 55/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0309 - val_loss: 0.0022 - val_mae: 0.0345 - learning_rate: 0.0019\n",
            "Epoch 56/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0274 - val_loss: 0.0020 - val_mae: 0.0335 - learning_rate: 0.0019\n",
            "Epoch 57/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0286 - val_loss: 0.0020 - val_mae: 0.0324 - learning_rate: 0.0018\n",
            "Epoch 58/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0288 - val_loss: 0.0020 - val_mae: 0.0332 - learning_rate: 0.0018\n",
            "Epoch 59/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0280 - val_loss: 0.0021 - val_mae: 0.0332 - learning_rate: 0.0017\n",
            "Epoch 60/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0276 - val_loss: 0.0020 - val_mae: 0.0331 - learning_rate: 0.0017\n",
            "Epoch 61/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0282 - val_loss: 0.0020 - val_mae: 0.0324 - learning_rate: 0.0016\n",
            "Epoch 62/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0278 - val_loss: 0.0020 - val_mae: 0.0329 - learning_rate: 0.0016\n",
            "Epoch 63/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0287 - val_loss: 0.0021 - val_mae: 0.0329 - learning_rate: 0.0015\n",
            "Epoch 64/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0304 - val_loss: 0.0019 - val_mae: 0.0322 - learning_rate: 0.0015\n",
            "Epoch 65/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0280 - val_loss: 0.0020 - val_mae: 0.0321 - learning_rate: 0.0014\n",
            "Epoch 66/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0283 - val_loss: 0.0019 - val_mae: 0.0322 - learning_rate: 0.0014\n",
            "Epoch 67/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0282 - val_loss: 0.0020 - val_mae: 0.0330 - learning_rate: 0.0013\n",
            "Epoch 68/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0272 - val_loss: 0.0021 - val_mae: 0.0330 - learning_rate: 0.0013\n",
            "Epoch 69/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0289 - val_loss: 0.0019 - val_mae: 0.0321 - learning_rate: 0.0013\n",
            "Epoch 70/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0280 - val_loss: 0.0019 - val_mae: 0.0321 - learning_rate: 0.0012\n",
            "Epoch 71/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0292 - val_loss: 0.0018 - val_mae: 0.0318 - learning_rate: 0.0012\n",
            "Epoch 72/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0302 - val_loss: 0.0020 - val_mae: 0.0321 - learning_rate: 0.0012\n",
            "Epoch 73/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0305 - val_loss: 0.0019 - val_mae: 0.0320 - learning_rate: 0.0011\n",
            "Epoch 74/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0284 - val_loss: 0.0019 - val_mae: 0.0321 - learning_rate: 0.0011\n",
            "Epoch 75/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0020 - val_mae: 0.0322 - learning_rate: 0.0010\n",
            "Epoch 76/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 0.0019 - val_mae: 0.0318 - learning_rate: 0.0010\n",
            "Epoch 77/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0297 - val_loss: 0.0019 - val_mae: 0.0322 - learning_rate: 9.8776e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0286 - val_loss: 0.0019 - val_mae: 0.0315 - learning_rate: 9.5813e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0291 - val_loss: 0.0018 - val_mae: 0.0312 - learning_rate: 9.2938e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0281 - val_loss: 0.0020 - val_mae: 0.0320 - learning_rate: 9.0150e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0307 - val_loss: 0.0019 - val_mae: 0.0319 - learning_rate: 8.7446e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0273 - val_loss: 0.0019 - val_mae: 0.0312 - learning_rate: 8.4822e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0273 - val_loss: 0.0018 - val_mae: 0.0313 - learning_rate: 8.2278e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0278 - val_loss: 0.0019 - val_mae: 0.0315 - learning_rate: 7.9809e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0019 - val_mae: 0.0314 - learning_rate: 7.7415e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0019 - val_mae: 0.0316 - learning_rate: 7.5093e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0275 - val_loss: 0.0018 - val_mae: 0.0315 - learning_rate: 7.2840e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0278 - val_loss: 0.0018 - val_mae: 0.0310 - learning_rate: 7.0655e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0286 - val_loss: 0.0019 - val_mae: 0.0313 - learning_rate: 6.8535e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0285 - val_loss: 0.0019 - val_mae: 0.0314 - learning_rate: 6.6479e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0277 - val_loss: 0.0019 - val_mae: 0.0314 - learning_rate: 6.4485e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0274 - val_loss: 0.0019 - val_mae: 0.0312 - learning_rate: 6.2550e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0274 - val_loss: 0.0018 - val_mae: 0.0313 - learning_rate: 6.0674e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0277 - val_loss: 0.0019 - val_mae: 0.0316 - learning_rate: 5.8853e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0275 - val_loss: 0.0018 - val_mae: 0.0315 - learning_rate: 5.7088e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0278 - val_loss: 0.0018 - val_mae: 0.0313 - learning_rate: 5.5375e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0299 - val_loss: 0.0018 - val_mae: 0.0309 - learning_rate: 5.3714e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0294 - val_loss: 0.0018 - val_mae: 0.0309 - learning_rate: 5.2102e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0280 - val_loss: 0.0018 - val_mae: 0.0310 - learning_rate: 5.0539e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0263 - val_loss: 0.0018 - val_mae: 0.0312 - learning_rate: 4.9023e-04\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\n",
            "Train Metrics:\n",
            "MSE  : 0.0013\n",
            "RMSE : 0.0355\n",
            "R²   : 0.9974\n",
            "\n",
            "Validation Metrics:\n",
            "MSE  : 0.0018\n",
            "RMSE : 0.0423\n",
            "R²   : 0.9969\n",
            "\n",
            "Test Metrics:\n",
            "MSE  : 0.0018\n",
            "RMSE : 0.0420\n",
            "R²   : 0.9966\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_and_preprocess_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    X = df.drop('efficiency', axis=1)\n",
        "    y = df['efficiency']\n",
        "\n",
        "    scaler_X = MinMaxScaler(feature_range=(-1, 1))\n",
        "    X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "    scaler_y = MinMaxScaler(feature_range=(-1, 1))\n",
        "    y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y = load_and_preprocess_data(r'C:\\Users\\user\\OneDrive\\Desktop\\sneha\\PROJECT\\dataset\\original\\data_set.csv'  )\n",
        "\n",
        "# Define improved model\n",
        "model = Sequential([\n",
        "    Dense(40, activation='relu', kernel_initializer='he_normal', input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation='relu', kernel_initializer='he_normal'),\n",
        "    Dense(30, activation='relu', kernel_initializer='he_normal'),\n",
        "    Dense(40, activation='relu', kernel_initializer='he_normal'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# traingdx-like optimizer: SGD + momentum + LR decay\n",
        "initial_lr = 0.01\n",
        "momentum = 0.9\n",
        "\n",
        "def lr_schedule(epoch, lr):\n",
        "    decay_rate = 0.97\n",
        "    return initial_lr * (decay_rate ** epoch)\n",
        "\n",
        "optimizer = SGD(learning_rate=initial_lr, momentum=momentum)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    LearningRateScheduler(lr_schedule),\n",
        "    EarlyStopping(patience=15, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Train\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_val_pred = model.predict(X_val)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "def print_metrics(y_true, y_pred, dataset_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"\\n{dataset_name} Metrics:\")\n",
        "    print(f\"MSE  : {mse:.4f}\")\n",
        "    print(f\"RMSE : {rmse:.4f}\")\n",
        "    print(f\"R²   : {r2:.4f}\")\n",
        "\n",
        "print_metrics(y_train, y_train_pred, \"Train\")\n",
        "print_metrics(y_val, y_val_pred, \"Validation\")\n",
        "print_metrics(y_test, y_test_pred, \"Test\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOTaBR_EuLWd"
      },
      "source": [
        "traingdx-tansig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srIVtv2GuQDs",
        "outputId": "d55aca8c-250b-4b40-a263-edca7457878e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\anaconda3\\envs\\hydrogen\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 284ms/step - loss: 0.5041 - mae: 0.6305 - val_loss: 0.2008 - val_mae: 0.3898 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1614 - mae: 0.3370 - val_loss: 0.1988 - val_mae: 0.4038 - learning_rate: 0.0097\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - loss: 0.2103 - mae: 0.4051 - val_loss: 0.1341 - val_mae: 0.3225 - learning_rate: 0.0094\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.1414 - mae: 0.2858 - val_loss: 0.1261 - val_mae: 0.2988 - learning_rate: 0.0091\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1393 - mae: 0.3148 - val_loss: 0.1411 - val_mae: 0.3156 - learning_rate: 0.0089\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1319 - mae: 0.2798 - val_loss: 0.1057 - val_mae: 0.2227 - learning_rate: 0.0086\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1149 - mae: 0.2455 - val_loss: 0.0911 - val_mae: 0.2144 - learning_rate: 0.0083\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1122 - mae: 0.2457 - val_loss: 0.1032 - val_mae: 0.2615 - learning_rate: 0.0081\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0974 - mae: 0.2439 - val_loss: 0.0824 - val_mae: 0.2008 - learning_rate: 0.0078\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0946 - mae: 0.2096 - val_loss: 0.0788 - val_mae: 0.2051 - learning_rate: 0.0076\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0876 - mae: 0.2077 - val_loss: 0.0776 - val_mae: 0.1932 - learning_rate: 0.0074\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0692 - mae: 0.1806 - val_loss: 0.0678 - val_mae: 0.1702 - learning_rate: 0.0072\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0746 - mae: 0.1740 - val_loss: 0.0645 - val_mae: 0.1724 - learning_rate: 0.0069\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0669 - mae: 0.1668 - val_loss: 0.0634 - val_mae: 0.1772 - learning_rate: 0.0067\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0514 - mae: 0.1495 - val_loss: 0.0571 - val_mae: 0.1590 - learning_rate: 0.0065\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0532 - mae: 0.1479 - val_loss: 0.0559 - val_mae: 0.1648 - learning_rate: 0.0063\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0574 - mae: 0.1605 - val_loss: 0.0506 - val_mae: 0.1517 - learning_rate: 0.0061\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0531 - mae: 0.1525 - val_loss: 0.0497 - val_mae: 0.1596 - learning_rate: 0.0060\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0489 - mae: 0.1503 - val_loss: 0.0477 - val_mae: 0.1611 - learning_rate: 0.0058\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0407 - mae: 0.1382 - val_loss: 0.0426 - val_mae: 0.1469 - learning_rate: 0.0056\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0528 - mae: 0.1501 - val_loss: 0.0423 - val_mae: 0.1503 - learning_rate: 0.0054\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0339 - mae: 0.1198 - val_loss: 0.0378 - val_mae: 0.1284 - learning_rate: 0.0053\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0340 - mae: 0.1150 - val_loss: 0.0357 - val_mae: 0.1283 - learning_rate: 0.0051\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0329 - mae: 0.1191 - val_loss: 0.0346 - val_mae: 0.1359 - learning_rate: 0.0050\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0355 - mae: 0.1279 - val_loss: 0.0329 - val_mae: 0.1352 - learning_rate: 0.0048\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0319 - mae: 0.1262 - val_loss: 0.0312 - val_mae: 0.1310 - learning_rate: 0.0047\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0285 - mae: 0.1172 - val_loss: 0.0296 - val_mae: 0.1269 - learning_rate: 0.0045\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0269 - mae: 0.1092 - val_loss: 0.0280 - val_mae: 0.1209 - learning_rate: 0.0044\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 216ms/step - loss: 0.0230 - mae: 0.1018 - val_loss: 0.0268 - val_mae: 0.1126 - learning_rate: 0.0043\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0275 - mae: 0.1070 - val_loss: 0.0257 - val_mae: 0.1187 - learning_rate: 0.0041\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 0.0280 - mae: 0.1168 - val_loss: 0.0250 - val_mae: 0.1177 - learning_rate: 0.0040\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0239 - mae: 0.1115 - val_loss: 0.0243 - val_mae: 0.1193 - learning_rate: 0.0039\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0235 - mae: 0.1083 - val_loss: 0.0228 - val_mae: 0.1118 - learning_rate: 0.0038\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 275ms/step - loss: 0.0205 - mae: 0.0960 - val_loss: 0.0224 - val_mae: 0.1022 - learning_rate: 0.0037\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - loss: 0.0186 - mae: 0.0947 - val_loss: 0.0211 - val_mae: 0.1060 - learning_rate: 0.0036\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 271ms/step - loss: 0.0197 - mae: 0.0967 - val_loss: 0.0205 - val_mae: 0.1061 - learning_rate: 0.0034\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0169 - mae: 0.0912 - val_loss: 0.0198 - val_mae: 0.0973 - learning_rate: 0.0033\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0171 - mae: 0.0879 - val_loss: 0.0189 - val_mae: 0.0976 - learning_rate: 0.0032\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0160 - mae: 0.0862 - val_loss: 0.0186 - val_mae: 0.0993 - learning_rate: 0.0031\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - loss: 0.0154 - mae: 0.0851 - val_loss: 0.0178 - val_mae: 0.0918 - learning_rate: 0.0030\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0181 - mae: 0.0922 - val_loss: 0.0173 - val_mae: 0.0911 - learning_rate: 0.0030\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 287ms/step - loss: 0.0171 - mae: 0.0897 - val_loss: 0.0170 - val_mae: 0.0890 - learning_rate: 0.0029\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - loss: 0.0139 - mae: 0.0786 - val_loss: 0.0168 - val_mae: 0.0887 - learning_rate: 0.0028\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - loss: 0.0148 - mae: 0.0819 - val_loss: 0.0163 - val_mae: 0.0900 - learning_rate: 0.0027\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292ms/step - loss: 0.0124 - mae: 0.0757 - val_loss: 0.0161 - val_mae: 0.0901 - learning_rate: 0.0026\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 313ms/step - loss: 0.0138 - mae: 0.0811 - val_loss: 0.0157 - val_mae: 0.0884 - learning_rate: 0.0025\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0140 - mae: 0.0824 - val_loss: 0.0154 - val_mae: 0.0855 - learning_rate: 0.0025\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0153 - mae: 0.0843 - val_loss: 0.0152 - val_mae: 0.0850 - learning_rate: 0.0024\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0146 - mae: 0.0802 - val_loss: 0.0150 - val_mae: 0.0854 - learning_rate: 0.0023\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - loss: 0.0114 - mae: 0.0717 - val_loss: 0.0147 - val_mae: 0.0856 - learning_rate: 0.0022\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0136 - mae: 0.0820 - val_loss: 0.0145 - val_mae: 0.0853 - learning_rate: 0.0022\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - loss: 0.0140 - mae: 0.0799 - val_loss: 0.0142 - val_mae: 0.0848 - learning_rate: 0.0021\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - loss: 0.0138 - mae: 0.0821 - val_loss: 0.0140 - val_mae: 0.0840 - learning_rate: 0.0021\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0105 - mae: 0.0689 - val_loss: 0.0137 - val_mae: 0.0825 - learning_rate: 0.0020\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - loss: 0.0148 - mae: 0.0825 - val_loss: 0.0135 - val_mae: 0.0813 - learning_rate: 0.0019\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step - loss: 0.0143 - mae: 0.0816 - val_loss: 0.0134 - val_mae: 0.0813 - learning_rate: 0.0019\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 352ms/step - loss: 0.0126 - mae: 0.0750 - val_loss: 0.0133 - val_mae: 0.0808 - learning_rate: 0.0018\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 206ms/step - loss: 0.0111 - mae: 0.0705 - val_loss: 0.0133 - val_mae: 0.0801 - learning_rate: 0.0018\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - loss: 0.0123 - mae: 0.0757 - val_loss: 0.0132 - val_mae: 0.0811 - learning_rate: 0.0017\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 524ms/step - loss: 0.0105 - mae: 0.0694 - val_loss: 0.0131 - val_mae: 0.0818 - learning_rate: 0.0017\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 409ms/step - loss: 0.0111 - mae: 0.0711 - val_loss: 0.0129 - val_mae: 0.0808 - learning_rate: 0.0016\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0138 - mae: 0.0812 - val_loss: 0.0128 - val_mae: 0.0803 - learning_rate: 0.0016\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - loss: 0.0108 - mae: 0.0715 - val_loss: 0.0127 - val_mae: 0.0793 - learning_rate: 0.0015\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - loss: 0.0102 - mae: 0.0692 - val_loss: 0.0126 - val_mae: 0.0788 - learning_rate: 0.0015\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 266ms/step - loss: 0.0113 - mae: 0.0726 - val_loss: 0.0125 - val_mae: 0.0789 - learning_rate: 0.0014\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0120 - mae: 0.0733 - val_loss: 0.0124 - val_mae: 0.0785 - learning_rate: 0.0014\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 339ms/step - loss: 0.0101 - mae: 0.0667 - val_loss: 0.0124 - val_mae: 0.0776 - learning_rate: 0.0013\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - loss: 0.0111 - mae: 0.0722 - val_loss: 0.0123 - val_mae: 0.0777 - learning_rate: 0.0013\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0097 - mae: 0.0684 - val_loss: 0.0122 - val_mae: 0.0786 - learning_rate: 0.0013\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0104 - mae: 0.0720 - val_loss: 0.0122 - val_mae: 0.0790 - learning_rate: 0.0012\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0110 - mae: 0.0734 - val_loss: 0.0122 - val_mae: 0.0796 - learning_rate: 0.0012\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0120 - mae: 0.0762 - val_loss: 0.0121 - val_mae: 0.0801 - learning_rate: 0.0012\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0090 - mae: 0.0647 - val_loss: 0.0120 - val_mae: 0.0785 - learning_rate: 0.0011\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0104 - mae: 0.0712 - val_loss: 0.0119 - val_mae: 0.0775 - learning_rate: 0.0011\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0110 - mae: 0.0726 - val_loss: 0.0119 - val_mae: 0.0766 - learning_rate: 0.0010\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0104 - mae: 0.0695 - val_loss: 0.0119 - val_mae: 0.0766 - learning_rate: 0.0010\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0108 - mae: 0.0723 - val_loss: 0.0119 - val_mae: 0.0764 - learning_rate: 9.8776e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0102 - mae: 0.0694 - val_loss: 0.0118 - val_mae: 0.0766 - learning_rate: 9.5813e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0124 - mae: 0.0777 - val_loss: 0.0117 - val_mae: 0.0770 - learning_rate: 9.2938e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0101 - mae: 0.0715 - val_loss: 0.0117 - val_mae: 0.0772 - learning_rate: 9.0150e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 319ms/step - loss: 0.0111 - mae: 0.0727 - val_loss: 0.0117 - val_mae: 0.0768 - learning_rate: 8.7446e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0115 - mae: 0.0756 - val_loss: 0.0116 - val_mae: 0.0766 - learning_rate: 8.4822e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 214ms/step - loss: 0.0108 - mae: 0.0733 - val_loss: 0.0116 - val_mae: 0.0760 - learning_rate: 8.2278e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0112 - mae: 0.0736 - val_loss: 0.0115 - val_mae: 0.0759 - learning_rate: 7.9809e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 205ms/step - loss: 0.0085 - mae: 0.0651 - val_loss: 0.0115 - val_mae: 0.0760 - learning_rate: 7.7415e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0116 - mae: 0.0760 - val_loss: 0.0115 - val_mae: 0.0758 - learning_rate: 7.5093e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0097 - mae: 0.0684 - val_loss: 0.0114 - val_mae: 0.0759 - learning_rate: 7.2840e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0091 - mae: 0.0663 - val_loss: 0.0114 - val_mae: 0.0757 - learning_rate: 7.0655e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0111 - mae: 0.0731 - val_loss: 0.0114 - val_mae: 0.0753 - learning_rate: 6.8535e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0100 - mae: 0.0721 - val_loss: 0.0114 - val_mae: 0.0752 - learning_rate: 6.6479e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0092 - mae: 0.0665 - val_loss: 0.0114 - val_mae: 0.0751 - learning_rate: 6.4485e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0097 - mae: 0.0684 - val_loss: 0.0114 - val_mae: 0.0748 - learning_rate: 6.2550e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step - loss: 0.0094 - mae: 0.0672 - val_loss: 0.0113 - val_mae: 0.0748 - learning_rate: 6.0674e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - loss: 0.0113 - mae: 0.0742 - val_loss: 0.0113 - val_mae: 0.0753 - learning_rate: 5.8853e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0099 - mae: 0.0700 - val_loss: 0.0113 - val_mae: 0.0754 - learning_rate: 5.7088e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - loss: 0.0082 - mae: 0.0640 - val_loss: 0.0113 - val_mae: 0.0752 - learning_rate: 5.5375e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0111 - mae: 0.0715 - val_loss: 0.0113 - val_mae: 0.0749 - learning_rate: 5.3714e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0105 - mae: 0.0715 - val_loss: 0.0113 - val_mae: 0.0747 - learning_rate: 5.2102e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0107 - mae: 0.0730 - val_loss: 0.0113 - val_mae: 0.0746 - learning_rate: 5.0539e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0087 - mae: 0.0642 - val_loss: 0.0112 - val_mae: 0.0750 - learning_rate: 4.9023e-04\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\n",
            "Train Metrics:\n",
            "MSE  : 0.0101\n",
            "RMSE : 0.1003\n",
            "R²   : 0.9789\n",
            "\n",
            "Validation Metrics:\n",
            "MSE  : 0.0112\n",
            "RMSE : 0.1060\n",
            "R²   : 0.9803\n",
            "\n",
            "Test Metrics:\n",
            "MSE  : 0.0235\n",
            "RMSE : 0.1534\n",
            "R²   : 0.9542\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_and_preprocess_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    X = df.drop('efficiency', axis=1)\n",
        "    y = df['efficiency']\n",
        "\n",
        "    scaler_X = MinMaxScaler(feature_range=(-1, 1))\n",
        "    X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "    scaler_y = MinMaxScaler(feature_range=(-1, 1))\n",
        "    y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y = load_and_preprocess_data(r'C:\\Users\\user\\OneDrive\\Desktop\\sneha\\PROJECT\\dataset\\original\\data_set.csv'  )\n",
        "\n",
        "# Define improved MLP model with tansig (tanh) activation and specified neurons\n",
        "model = Sequential([\n",
        "    Dense(20, activation='tanh', input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation='tanh'),\n",
        "    Dense(40, activation='tanh'),\n",
        "    Dense(30, activation='tanh'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# traingdx-like optimizer: SGD + momentum + learning rate decay\n",
        "initial_lr = 0.01\n",
        "momentum = 0.9\n",
        "\n",
        "def lr_schedule(epoch, lr):\n",
        "    decay_rate = 0.97\n",
        "    return initial_lr * (decay_rate ** epoch)\n",
        "\n",
        "optimizer = SGD(learning_rate=initial_lr, momentum=momentum)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    LearningRateScheduler(lr_schedule),\n",
        "    EarlyStopping(patience=15, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Train\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_val_pred = model.predict(X_val)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "def print_metrics(y_true, y_pred, dataset_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"\\n{dataset_name} Metrics:\")\n",
        "    print(f\"MSE  : {mse:.4f}\")\n",
        "    print(f\"RMSE : {rmse:.4f}\")\n",
        "    print(f\"R²   : {r2:.4f}\")\n",
        "\n",
        "print_metrics(y_train, y_train_pred, \"Train\")\n",
        "print_metrics(y_val, y_val_pred, \"Validation\")\n",
        "print_metrics(y_test, y_test_pred, \"Test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWJJJ3482_4G"
      },
      "source": [
        "traingdm, logsig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpOWm_Balurf",
        "outputId": "f237b412-0d63-4748-ce96-8b06c931a1e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.5287 - mae: 0.5832 - val_loss: 0.5785 - val_mae: 0.6549\n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4842 - mae: 0.5833 - val_loss: 0.6324 - val_mae: 0.6394\n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5648 - mae: 0.6232 - val_loss: 0.6947 - val_mae: 0.6292\n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4834 - mae: 0.5574 - val_loss: 0.5961 - val_mae: 0.7145\n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5604 - mae: 0.6350 - val_loss: 0.5726 - val_mae: 0.6806\n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5075 - mae: 0.5959 - val_loss: 0.5700 - val_mae: 0.6727\n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5186 - mae: 0.6317 - val_loss: 0.6216 - val_mae: 0.6407\n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4776 - mae: 0.5544 - val_loss: 0.5694 - val_mae: 0.6691\n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4415 - mae: 0.5302 - val_loss: 0.5892 - val_mae: 0.6489\n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5278 - mae: 0.6188 - val_loss: 0.5736 - val_mae: 0.6560\n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5138 - mae: 0.5908 - val_loss: 0.5979 - val_mae: 0.6459\n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4647 - mae: 0.5600 - val_loss: 0.5691 - val_mae: 0.6634\n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5090 - mae: 0.6051 - val_loss: 0.6646 - val_mae: 0.6321\n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5358 - mae: 0.5789 - val_loss: 0.5726 - val_mae: 0.6557\n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3905 - mae: 0.4880 - val_loss: 0.6401 - val_mae: 0.7537\n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6181 - mae: 0.7098 - val_loss: 0.6236 - val_mae: 0.6390\n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4755 - mae: 0.5793 - val_loss: 0.6673 - val_mae: 0.6311\n",
            "Epoch 18/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5174 - mae: 0.5413 - val_loss: 0.5940 - val_mae: 0.7135\n",
            "Epoch 19/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5138 - mae: 0.6070 - val_loss: 0.5833 - val_mae: 0.6493\n",
            "Epoch 20/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5233 - mae: 0.6202 - val_loss: 0.6173 - val_mae: 0.6397\n",
            "Epoch 21/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4886 - mae: 0.5797 - val_loss: 0.5867 - val_mae: 0.6477\n",
            "Epoch 22/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4587 - mae: 0.5588 - val_loss: 0.5700 - val_mae: 0.6558\n",
            "Epoch 23/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4436 - mae: 0.5637 - val_loss: 0.5705 - val_mae: 0.6552\n",
            "Epoch 24/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4804 - mae: 0.5816 - val_loss: 0.6139 - val_mae: 0.6398\n",
            "Epoch 25/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5149 - mae: 0.5874 - val_loss: 0.5876 - val_mae: 0.6466\n",
            "Epoch 26/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4650 - mae: 0.5591 - val_loss: 0.5688 - val_mae: 0.6561\n",
            "Epoch 27/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4895 - mae: 0.5864 - val_loss: 0.5714 - val_mae: 0.6842\n",
            "Epoch 28/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5084 - mae: 0.6202 - val_loss: 0.7186 - val_mae: 0.6224\n",
            "Epoch 29/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5225 - mae: 0.5660 - val_loss: 0.5700 - val_mae: 0.6538\n",
            "Epoch 30/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4732 - mae: 0.5454 - val_loss: 0.5736 - val_mae: 0.6888\n",
            "Epoch 31/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5306 - mae: 0.6513 - val_loss: 0.7150 - val_mae: 0.6223\n",
            "Epoch 32/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4257 - mae: 0.4870 - val_loss: 0.6422 - val_mae: 0.7561\n",
            "Epoch 33/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5776 - mae: 0.6701 - val_loss: 0.5713 - val_mae: 0.6518\n",
            "Epoch 34/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4455 - mae: 0.5699 - val_loss: 0.5695 - val_mae: 0.6527\n",
            "Epoch 35/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5193 - mae: 0.6221 - val_loss: 0.6795 - val_mae: 0.6263\n",
            "Epoch 36/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5144 - mae: 0.5433 - val_loss: 0.6057 - val_mae: 0.7263\n",
            "Epoch 37/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5529 - mae: 0.6624 - val_loss: 0.6282 - val_mae: 0.6343\n",
            "Epoch 38/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5143 - mae: 0.6108 - val_loss: 0.6106 - val_mae: 0.6377\n",
            "Epoch 39/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5216 - mae: 0.5485 - val_loss: 0.5918 - val_mae: 0.7134\n",
            "Epoch 40/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5023 - mae: 0.5980 - val_loss: 0.5634 - val_mae: 0.6642\n",
            "Epoch 41/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5262 - mae: 0.6500 - val_loss: 0.6155 - val_mae: 0.6359\n",
            "Epoch 42/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4445 - mae: 0.5115 - val_loss: 0.6125 - val_mae: 0.7324\n",
            "Epoch 43/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5880 - mae: 0.6893 - val_loss: 0.6684 - val_mae: 0.6262\n",
            "Epoch 44/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4936 - mae: 0.5601 - val_loss: 0.5623 - val_mae: 0.6651\n",
            "Epoch 45/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4741 - mae: 0.5702 - val_loss: 0.5967 - val_mae: 0.6392\n",
            "Epoch 46/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5955 - mae: 0.6707 - val_loss: 0.6550 - val_mae: 0.6274\n",
            "Epoch 47/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4655 - mae: 0.5364 - val_loss: 0.5684 - val_mae: 0.6848\n",
            "Epoch 48/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4868 - mae: 0.6095 - val_loss: 0.5623 - val_mae: 0.6548\n",
            "Epoch 49/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4846 - mae: 0.6009 - val_loss: 0.5898 - val_mae: 0.6396\n",
            "Epoch 50/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4695 - mae: 0.5618 - val_loss: 0.5694 - val_mae: 0.6466\n",
            "Epoch 51/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4902 - mae: 0.5927 - val_loss: 0.5685 - val_mae: 0.6465\n",
            "Epoch 52/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4240 - mae: 0.5246 - val_loss: 0.5593 - val_mae: 0.6608\n",
            "Epoch 53/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4631 - mae: 0.5797 - val_loss: 0.5816 - val_mae: 0.6402\n",
            "Epoch 54/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4892 - mae: 0.6048 - val_loss: 0.5586 - val_mae: 0.6574\n",
            "Epoch 55/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4672 - mae: 0.5781 - val_loss: 0.6311 - val_mae: 0.6278\n",
            "Epoch 56/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4620 - mae: 0.5307 - val_loss: 0.5880 - val_mae: 0.7125\n",
            "Epoch 57/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5304 - mae: 0.6251 - val_loss: 0.5672 - val_mae: 0.6432\n",
            "Epoch 58/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4490 - mae: 0.5651 - val_loss: 0.5906 - val_mae: 0.6347\n",
            "Epoch 59/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4602 - mae: 0.5463 - val_loss: 0.5558 - val_mae: 0.6546\n",
            "Epoch 60/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4640 - mae: 0.5608 - val_loss: 0.5546 - val_mae: 0.6596\n",
            "Epoch 61/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4926 - mae: 0.6050 - val_loss: 0.5941 - val_mae: 0.6316\n",
            "Epoch 62/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5556 - mae: 0.6330 - val_loss: 0.5721 - val_mae: 0.6370\n",
            "Epoch 63/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5109 - mae: 0.5687 - val_loss: 0.5521 - val_mae: 0.6564\n",
            "Epoch 64/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4724 - mae: 0.5736 - val_loss: 0.5888 - val_mae: 0.6303\n",
            "Epoch 65/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4149 - mae: 0.5201 - val_loss: 0.5503 - val_mae: 0.6588\n",
            "Epoch 66/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4534 - mae: 0.5668 - val_loss: 0.5585 - val_mae: 0.6381\n",
            "Epoch 67/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4890 - mae: 0.5807 - val_loss: 0.5523 - val_mae: 0.6404\n",
            "Epoch 68/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4761 - mae: 0.5734 - val_loss: 0.5471 - val_mae: 0.6486\n",
            "Epoch 69/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4473 - mae: 0.5486 - val_loss: 0.5649 - val_mae: 0.6309\n",
            "Epoch 70/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3743 - mae: 0.4934 - val_loss: 0.5468 - val_mae: 0.6393\n",
            "Epoch 71/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4690 - mae: 0.5884 - val_loss: 0.5676 - val_mae: 0.6265\n",
            "Epoch 72/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4786 - mae: 0.5687 - val_loss: 0.5407 - val_mae: 0.6439\n",
            "Epoch 73/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4918 - mae: 0.5888 - val_loss: 0.5760 - val_mae: 0.6202\n",
            "Epoch 74/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4469 - mae: 0.5550 - val_loss: 0.5385 - val_mae: 0.6353\n",
            "Epoch 75/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4789 - mae: 0.5852 - val_loss: 0.5577 - val_mae: 0.6204\n",
            "Epoch 76/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3913 - mae: 0.5059 - val_loss: 0.5309 - val_mae: 0.6423\n",
            "Epoch 77/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4114 - mae: 0.5235 - val_loss: 0.5601 - val_mae: 0.6138\n",
            "Epoch 78/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5037 - mae: 0.6055 - val_loss: 0.5972 - val_mae: 0.6025\n",
            "Epoch 79/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5834 - mae: 0.5409 - val_loss: 0.6111 - val_mae: 0.7429\n",
            "Epoch 80/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5010 - mae: 0.6200 - val_loss: 0.5916 - val_mae: 0.5973\n",
            "Epoch 81/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3752 - mae: 0.5063 - val_loss: 0.5153 - val_mae: 0.6411\n",
            "Epoch 82/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4231 - mae: 0.5325 - val_loss: 0.5097 - val_mae: 0.6284\n",
            "Epoch 83/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3971 - mae: 0.5335 - val_loss: 0.5125 - val_mae: 0.6055\n",
            "Epoch 84/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4615 - mae: 0.5956 - val_loss: 0.5573 - val_mae: 0.5840\n",
            "Epoch 85/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4173 - mae: 0.4805 - val_loss: 0.5162 - val_mae: 0.6685\n",
            "Epoch 86/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4557 - mae: 0.6027 - val_loss: 0.6303 - val_mae: 0.5593\n",
            "Epoch 87/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5357 - mae: 0.5786 - val_loss: 0.4806 - val_mae: 0.5919\n",
            "Epoch 88/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4571 - mae: 0.5164 - val_loss: 0.4822 - val_mae: 0.6416\n",
            "Epoch 89/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4120 - mae: 0.5616 - val_loss: 0.5053 - val_mae: 0.5520\n",
            "Epoch 90/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3605 - mae: 0.4710 - val_loss: 0.4452 - val_mae: 0.5916\n",
            "Epoch 91/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4386 - mae: 0.5849 - val_loss: 0.5993 - val_mae: 0.5343\n",
            "Epoch 92/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4695 - mae: 0.5358 - val_loss: 0.4235 - val_mae: 0.5389\n",
            "Epoch 93/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3543 - mae: 0.4438 - val_loss: 0.4042 - val_mae: 0.5831\n",
            "Epoch 94/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3595 - mae: 0.5276 - val_loss: 0.4420 - val_mae: 0.4753\n",
            "Epoch 95/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3130 - mae: 0.4306 - val_loss: 0.3862 - val_mae: 0.4719\n",
            "Epoch 96/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3373 - mae: 0.4570 - val_loss: 0.3613 - val_mae: 0.4480\n",
            "Epoch 97/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3326 - mae: 0.4632 - val_loss: 0.3409 - val_mae: 0.4159\n",
            "Epoch 98/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2898 - mae: 0.4040 - val_loss: 0.2743 - val_mae: 0.4382\n",
            "Epoch 99/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2291 - mae: 0.4116 - val_loss: 0.2674 - val_mae: 0.3791\n",
            "Epoch 100/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1973 - mae: 0.3403 - val_loss: 0.2166 - val_mae: 0.3980\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "\n",
            "Train Metrics:\n",
            "MSE  : 0.1953\n",
            "RMSE : 0.4419\n",
            "R²   : 0.5904\n",
            "\n",
            "Validation Metrics:\n",
            "MSE  : 0.2166\n",
            "RMSE : 0.4654\n",
            "R²   : 0.6196\n",
            "\n",
            "Test Metrics:\n",
            "MSE  : 0.1982\n",
            "RMSE : 0.4452\n",
            "R²   : 0.6148\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_and_preprocess_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    X = df.drop('efficiency', axis=1)\n",
        "    y = df['efficiency']\n",
        "\n",
        "    scaler_X = MinMaxScaler(feature_range=(-1, 1))\n",
        "    X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "    scaler_y = MinMaxScaler(feature_range=(-1, 1))\n",
        "    y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y = load_and_preprocess_data(r'C:\\Users\\user\\OneDrive\\Desktop\\sneha\\PROJECT\\dataset\\original\\data_set.csv'  )\n",
        "\n",
        "# Define MLP model with logsig activation and traingdm-like optimizer\n",
        "model = Sequential([\n",
        "    Dense(20, activation='sigmoid', input_shape=(X_train.shape[1],)),\n",
        "    Dense(40, activation='sigmoid'),\n",
        "    Dense(40, activation='sigmoid'),\n",
        "    Dense(40, activation='sigmoid'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# traingdm-like optimizer: SGD with momentum (no LR decay)\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=15, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_val_pred = model.predict(X_val)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation function\n",
        "def print_metrics(y_true, y_pred, dataset_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"\\n{dataset_name} Metrics:\")\n",
        "    print(f\"MSE  : {mse:.4f}\")\n",
        "    print(f\"RMSE : {rmse:.4f}\")\n",
        "    print(f\"R²   : {r2:.4f}\")\n",
        "\n",
        "# Print metrics\n",
        "print_metrics(y_train, y_train_pred, \"Train\")\n",
        "print_metrics(y_val, y_val_pred, \"Validation\")\n",
        "print_metrics(y_test, y_test_pred, \"Test\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hydrogen",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
